{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DLCV_HW4_P1.ipynb","provenance":[],"collapsed_sections":["ovsqwqPWvyBb","ua7KPHfuvzXA","ZPGcn_Obv1m2"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"VQgbTlnGpyBP"},"source":["# **Homework #4_P1**"]},{"cell_type":"markdown","metadata":{"id":"ueEcGWqXp5bw"},"source":["## **Problem 1: Prototypical Network (50%)**\r\n","### **Task Definition**\r\n","In this problem, you will have to implement the prototypical network. Prototypical Networks learn a metric space in which classification can be performed by computing distances to prototype representations of each class."]},{"cell_type":"markdown","metadata":{"id":"p9fg3F4wtvFC"},"source":["Hint   \r\n","1. For the model architecture, the CNN Feature Extractor is\r\n","provided in P.26. You only need to design the architecture of\r\n","the MLP.    \r\n","2. For the objective function, you can only use the cross\r\n","entropy loss."]},{"cell_type":"markdown","metadata":{"id":"_4dQsokgqXg1"},"source":["# Model Performance (15%)\r\n","• The mean accuracy of your model under **5-way 1-shot** setting (during inference) (Problem 1-1) should be above the baseline score.\r\n","*   On the validation set (10%): **0.44** [should be reported in Problem 1-1]\r\n","*   On the test set (5%): **0.42**\r\n","\r\n","• You have to use the test case provided by the TAs to calculate your mean accuracy on the validation set.   \r\n","• TAs will execute your code to check if you pass the baseline.   \r\n","• Only TAs have the test data."]},{"cell_type":"code","metadata":{"id":"zKjzFCVAprCH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608561192502,"user_tz":-480,"elapsed":1037,"user":{"displayName":"GOD DP","photoUrl":"","userId":"07949532058692121683"}},"outputId":"cde66f43-7a2e-469c-bd41-101b1c52b4a2"},"source":["# connect to drive\r\n","from google.colab import drive\r\n","drive.mount(\"/content/drive\", force_remount=True)\r\n","path = 'drive/My Drive/senior_1/DLCV/HW/hw4'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"30RyYqyvtMx1"},"source":["!gdown --id '1Ez4TCdglld8vNjtIFSUyqy8l09cPkrdW' --output hw4_data.zip # 下載資料集\r\n","!unzip hw4_data.zip # 解壓縮\r\n","\r\n","'''\r\n","    The dataset consists of 48,000 84x84 RGB images in 80 classes.\r\n","    1. train                  # training images directory (64 class, each class has 600 images)\r\n","    2. val                    # validation images directory (16 class, each class has 600 images)\r\n","    3. train.csv              # training image csv file\r\n","    4. val.csv                # validation image csv file\r\n","    5. val_testcase.csv       # validation test case file\r\n","    6. val_testcase_gt.csv    # ground truth for validation test case\r\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZQugwpaRtYmr"},"source":["# set packages\r\n","!pip3 install certifi==2020.6.20\r\n","!pip3 install cycler==0.10.0\r\n","!pip3 install joblib==0.17.0\r\n","!pip3 install kiwisolver==1.2.0\r\n","!pip3 install matplotlib==3.3.2\r\n","!pip3 install numpy==1.18.1\r\n","!pip3 install pandas==1.1.3\r\n","!pip3 install Pillow==8.0.0\r\n","!pip3 install pyparsing==2.4.7\r\n","!pip3 install python-dateutil==2.8.1\r\n","!pip3 install pytz==2020.1\r\n","!pip3 install scikit-learn==0.21.3\r\n","!pip3 install scipy==1.2.1\r\n","!pip3 install six==1.15.0\r\n","!pip3 install torch==1.4.0\r\n","!pip3 install torchvision==0.5.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-GfT2Pq4td6-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608640320712,"user_tz":-480,"elapsed":26722,"user":{"displayName":"曹林熹","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1rp1WgUEEdLYBSWWUtH2FPvqx3Hdazi01GHGD=s64","userId":"06338317211672502600"}},"outputId":"92f15564-24c0-4123-d776-367ac737fa7b"},"source":["# Import 需要的套件\r\n","import os\r\n","import numpy as np\r\n","import torch\r\n","import torch.nn as nn\r\n","import torchvision.models as models\r\n","import torchvision\r\n","from torch.utils.data import DataLoader, Dataset\r\n","import torchvision.transforms as transforms\r\n","from torch.utils.data.sampler import Sampler\r\n","import time\r\n","import pandas as pd\r\n","import random\r\n","import scipy.misc\r\n","import argparse\r\n","import imageio\r\n","from torch.autograd import Variable\r\n","from torch.optim import Adam, AdamW\r\n","import csv\r\n","from sklearn.manifold import TSNE\r\n","from PIL import Image\r\n","\r\n","# 固定隨機種子\r\n","def same_seeds(seed=123):\r\n","    torch.manual_seed(seed)\r\n","    if torch.cuda.is_available():\r\n","        torch.cuda.manual_seed(seed)\r\n","        torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\r\n","    np.random.seed(seed)  # Numpy module.\r\n","    random.seed(seed)  # Python random module.\r\n","    torch.backends.cudnn.benchmark = False\r\n","    torch.backends.cudnn.deterministic = True\r\n","    print(\"torchvision.__version__ =\", torchvision.__version__)\r\n","    print(\"torch.cuda.is_available() =\", torch.cuda.is_available())\r\n","\r\n","same_seeds(123)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torchvision.__version__ = 0.8.1+cu101\n","torch.cuda.is_available() = True\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pqLXGtXQtbNm"},"source":["# Dataset\r\n","在 PyTorch 中，我們可以利用 torch.utils.data 的 Dataset 及 DataLoader 來\"包裝\" data，使後續的 training 及 testing 更為方便。\r\n","\r\n","Dataset 需要 overload 兩個函數：\\_\\_len\\_\\_ 及 \\_\\_getitem\\_\\_\r\n","\r\n","\\_\\_len\\_\\_ 必須要回傳 dataset 的大小，而 \\_\\_getitem\\_\\_ 則定義了當程式利用 [ ] 取值時，dataset 應該要怎麼回傳資料。\r\n","\r\n","實際上我們並不會直接使用到這兩個函數，但是使用 DataLoader 在 enumerate Dataset 時會使用到，沒有實做的話會在程式運行階段出現 error。\r\n"]},{"cell_type":"code","metadata":{"id":"9U_5NKehtZ27"},"source":["# mini-Imagenet dataset\r\n","filenameToPILImage = lambda x: Image.open(x)  \r\n","\r\n","class MiniDataset(Dataset):\r\n","    def __init__(self, csv_path, data_dir, mode):\r\n","        self.data_dir = data_dir\r\n","        self.data_df = pd.read_csv(csv_path).set_index(\"id\") # 把 index 設成 id\r\n","        self.mode = mode\r\n","\r\n","        # training 時需做 data augmentation\r\n","        self.train_transform = transforms.Compose([\r\n","            filenameToPILImage, # 轉成 python 圖片\r\n","            transforms.RandomHorizontalFlip(), # 隨機將圖片水平翻轉\r\n","            transforms.RandomRotation(15), # 隨機旋轉圖片，表示在（-15，+15）之間隨機旋轉，旋轉後空的地方補 0\r\n","            transforms.ToTensor(), # 將圖片轉成 Tensor，並把數值 normalize 到 [0,1] (data normalization) ps. Tensor 為多維張量\r\n","            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # normalize\r\n","        ])\r\n","\r\n","        # testing 時不需做 data augmentation\r\n","        self.test_transform = transforms.Compose([\r\n","            filenameToPILImage,                                    \r\n","            transforms.ToTensor(),\r\n","            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # normalize\r\n","        ])\r\n","\r\n","    def __getitem__(self, index):\r\n","        path = self.data_df.loc[index, \"filename\"]\r\n","        label = self.data_df.loc[index, \"label\"]\r\n","        if self.mode == 'train':\r\n","            image = self.train_transform(os.path.join(self.data_dir, path))\r\n","        else:\r\n","            image = self.test_transform(os.path.join(self.data_dir, path))\r\n","        return image, label\r\n","\r\n","    def __len__(self):\r\n","        return len(self.data_df)\r\n","\r\n","class GeneratorSampler(Sampler):\r\n","    def __init__(self, episode_file_path, mode):\r\n","        if mode == 'train':\r\n","            episode_df = episode_file_path.set_index(\"episode_id\")\r\n","        else:\r\n","            episode_df = pd.read_csv(episode_file_path).set_index(\"episode_id\")\r\n","        self.sampled_sequence = episode_df.values.flatten().tolist()\r\n","\r\n","    def __iter__(self):\r\n","        return iter(self.sampled_sequence) \r\n","\r\n","    def __len__(self):\r\n","        return len(self.sampled_sequence)\r\n","\r\n","# create N-way-K-shot traincase_csv\r\n","def create_traincase(N, K, N_query, num_episode, train_csv):\r\n","    column_name = ['episode_id']\r\n","    for n in range(N):\r\n","        for k in range(K):\r\n","            column_name.append('class{}_support{}'.format(str(n), str(k)))\r\n","    for q in range(N*N_query):\r\n","        column_name.append('query{}'.format(str(q)))\r\n","    traincase_csv = pd.DataFrame(np.zeros([num_episode, len(column_name)]), columns=column_name).astype(int)\r\n","    traincase_csv['episode_id'] = range(0, num_episode)\r\n","    \r\n","    train_data_index = pd.read_csv(train_csv)\r\n","    for episode in range(num_episode):\r\n","        sampling_class_list = [] # get N class\r\n","        sampling_support_list = []\r\n","        sampling_query_list = []\r\n","\r\n","        for i in np.random.choice(range(0, len(train_data_index['label'].unique())), N, replace=False):\r\n","            sampling_class_list.append(train_data_index['label'].unique()[i]) # get N different class\r\n","\r\n","        for sampling_class in sampling_class_list:\r\n","            data = train_data_index[train_data_index['label'] == sampling_class]['id'].reset_index()\r\n","            data_index =  np.random.choice(len(data), K + N_query, replace=False)\r\n","            for i in range(len(data_index)):\r\n","                if i < K:\r\n","                    sampling_support_list.append(data['id'][data_index[i]])\r\n","                else: \r\n","                    sampling_query_list.append(data['id'][data_index[i]])\r\n","\r\n","        for n in range(N):\r\n","            for k in range(K):\r\n","                traincase_csv.loc[episode, 'class{}_support{}'.format(str(n), str(k))] = sampling_support_list[n*K + k]\r\n","        for q in range(N*N_query):\r\n","            traincase_csv.loc[episode, 'query{}'.format(str(q))] = sampling_query_list[q]\r\n","\r\n","    return traincase_csv\r\n","\r\n","def worker_init_fn(worker_id):                                                          \r\n","    np.random.seed(np.random.get_state()[1][0] + worker_id)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ovsqwqPWvyBb"},"source":["# Model"]},{"cell_type":"code","metadata":{"id":"c5XWjlw7v4Jo"},"source":["class Convnet(nn.Module):\r\n","\r\n","    def __init__(self, in_channels = 3, hid_channels = 64, out_channels = 64):\r\n","        super(Convnet, self).__init__()\r\n","\r\n","        self.encoder = nn.Sequential(\r\n","            # input_size = (84, 84, 3)\r\n","            # output_size = (input_size-kernel_size+2*padding)/stride + 1\r\n","            nn.Conv2d(in_channels, hid_channels, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), \r\n","            nn.BatchNorm2d(hid_channels),\r\n","            nn.ReLU(),\r\n","            nn.MaxPool2d(2, 2, 0),\r\n","            # [batch_size, hid_channels, 42, 42]\r\n","\r\n","            nn.Conv2d(hid_channels, hid_channels, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), \r\n","            nn.BatchNorm2d(hid_channels),\r\n","            nn.ReLU(),\r\n","            nn.MaxPool2d(2, 2, 0),\r\n","            # [batch_size, hid_channels, 21, 21]\r\n","\r\n","            nn.Conv2d(hid_channels, hid_channels, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), \r\n","            nn.BatchNorm2d(hid_channels),\r\n","            nn.ReLU(),\r\n","            nn.MaxPool2d(2, 2, 0),\r\n","            # [batch_size, hid_channels, 10, 10]\r\n","\r\n","            nn.Conv2d(hid_channels, out_channels, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), \r\n","            nn.BatchNorm2d(out_channels),\r\n","            nn.ReLU(),\r\n","            nn.MaxPool2d(2, 2, 0),\r\n","            # [batch_size, out_channels, 5, 5]\r\n","\r\n","        )     \r\n","\r\n","    def forward(self, x):\r\n","        x = self.encoder(x)\r\n","        return x.view(x.size(0), -1) # [batch_size, out_channels*5*5]\r\n","\r\n","def euclidean_dist(x, y):\r\n","    # x: N x D ex. (75, 1600)\r\n","    # y: M x D ex. (5, 1600)\r\n","    n = x.size(0) # ex. 75\r\n","    m = y.size(0) # ex. 5\r\n","    d = x.size(1) # ex. dim = 1600\r\n","    assert d == y.size(1)\r\n","\r\n","    x = x.unsqueeze(1).expand(n, m, d)\r\n","    y = y.unsqueeze(0).expand(n, m, d)\r\n","\r\n","    return torch.pow(x - y, 2).sum(2) # ex. 75 個 data 對每一個 class (5 個) 的距離 (75, 5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ua7KPHfuvzXA"},"source":["# Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2VKeA0s-r4Wh","executionInfo":{"status":"ok","timestamp":1608354098377,"user_tz":-480,"elapsed":697,"user":{"displayName":"GOD DP","photoUrl":"","userId":"07949532058692121683"}},"outputId":"ba4e8ad9-f7fb-46e4-c661-16694cd90273"},"source":["# create N-way-K-shot train_loader\r\n","def create_train_loader(traincase_csv):\r\n","    train_loader = DataLoader(\r\n","            train_dataset, batch_size=train_N_way * (train_N_query + train_N_shot), num_workers=3, pin_memory=False, \r\n","            worker_init_fn=worker_init_fn, sampler=GeneratorSampler(traincase_csv, 'train'))\r\n","    return train_loader\r\n","\r\n","# set state\r\n","same_seeds(123) \r\n","\r\n","# set hyperparameters\r\n","train_N_way = 10\r\n","train_N_shot = 5 # first use 5 shot => 1 shot   \r\n","train_N_query = 15\r\n","val_N_way = 5\r\n","val_N_shot = 1    \r\n","val_N_query = 15\r\n","num_episode = 400  \r\n","\r\n","# set data path\r\n","workspace_dir = \"./hw4_data\"\r\n","train_csv = os.path.join(workspace_dir, \"train.csv\")\r\n","train_data_dir = os.path.join(workspace_dir, \"train\")\r\n","val_csv = os.path.join(workspace_dir, \"val.csv\")\r\n","val_data_dir = os.path.join(workspace_dir, \"val\")\r\n","valcase_csv = os.path.join(workspace_dir, \"val_testcase.csv\")\r\n","gt_csv = os.path.join(workspace_dir, \"val_testcase_gt.csv\")\r\n","output_csv = os.path.join(path, \"p1_output_{}way_{}shot.csv\".format(train_N_way, train_N_shot))\r\n","\r\n","# set dataset\r\n","train_dataset = MiniDataset(train_csv, train_data_dir, 'train')\r\n","val_dataset = MiniDataset(val_csv, val_data_dir, 'test')\r\n","print('finish dataset')\r\n","\r\n","val_loader = DataLoader(\r\n","        val_dataset, batch_size=val_N_way * (val_N_query + val_N_shot), num_workers=3, pin_memory=False, \r\n","        worker_init_fn=worker_init_fn, sampler=GeneratorSampler(valcase_csv, 'val'))\r\n","print('finish data_loader')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torchvision.__version__ = 0.5.0\n","torch.cuda.is_available() = True\n","finish dataset\n","finish data_loader\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PMSggbLsv3Yq"},"source":["# set model\r\n","if torch.cuda.is_available():\r\n","    convnet = Convnet().cuda()\r\n","else:\r\n","    convnet = Convnet()\r\n","\r\n","loss = nn.CrossEntropyLoss() # 因為是 classification task，所以 loss 使用 CrossEntropyLoss\r\n","convnet_optimizer = torch.optim.Adam(convnet.parameters(), lr=0.001) # optimizer 使用 Adam \r\n","softmax = nn.Softmax(dim=1)\r\n","\r\n","# set hyperparameters\r\n","num_epoch = 150\r\n","best_val_acc = 0.0\r\n","\r\n","for epoch in range(num_epoch):\r\n","    training_epoch_time = time.time()\r\n","    train_acc = 0.0\r\n","    train_loss = 0.0\r\n","    val_acc = 0.0\r\n","    val_loss = 0.0\r\n","    traincase_csv = create_traincase(N=train_N_way, K=train_N_shot, N_query=train_N_query, num_episode=num_episode, train_csv=train_csv)\r\n","    train_loader = create_train_loader(traincase_csv)\r\n","    print('finish train_loader')\r\n","\r\n","    convnet.train() \r\n","\r\n","    # each batch represent one episode (support data + query data)\r\n","    for i, (data, target) in enumerate(train_loader):\r\n","        if torch.cuda.is_available():\r\n","            data = data.cuda()\r\n","        # split data into support and query data\r\n","        support_input = data[:train_N_way*train_N_shot, :, :, :] \r\n","        query_input   = data[train_N_way*train_N_shot: , :, :, :]\r\n","        # create the relative label (0 ~ N_way-1) for query data\r\n","        label_encoder = {target[i*train_N_shot] : i for i in range(train_N_way)}\r\n","        if torch.cuda.is_available():\r\n","            query_label = torch.cuda.LongTensor([label_encoder[class_name] for class_name in target[train_N_way*train_N_shot:]])\r\n","        else:\r\n","            query_label = torch.LongTensor([label_encoder[class_name] for class_name in target[train_N_way*train_N_shot:]])\r\n","\r\n","        convnet_optimizer.zero_grad() # 用 optimizer 將 convnet 參數的 gradient 歸零\r\n","\r\n","        support_encode = convnet(support_input) # extract the feature of support\r\n","        query_encode = convnet(query_input) # extract the feature of query\r\n","        support_proto = support_encode.view(train_N_way, train_N_shot, -1).mean(1)\r\n","        dists = euclidean_dist(query_encode, support_proto) \r\n","        p = softmax(-dists)\r\n","\r\n","        batch_loss = loss(p, query_label) # 計算 loss （注意 prediction 跟 label 必須同時在 CPU 或是 GPU 上）\r\n","        batch_loss.backward() # 利用 back propagation 算出每個參數的 gradient\r\n","        convnet_optimizer.step() # 以 optimizer 用 gradient 更新參數值\r\n","\r\n","        train_acc += np.mean(np.argmax(p.cpu().data.numpy(), axis=1) == query_label.cpu().data.numpy())\r\n","        train_loss += batch_loss.item()\r\n","    \r\n","    convnet.eval()  \r\n","\r\n","    with torch.no_grad():\r\n","        for i, (data, target) in enumerate(val_loader):\r\n","            if torch.cuda.is_available():\r\n","                data = data.cuda()\r\n","            # split data into support and query data\r\n","            support_input = data[:val_N_way*val_N_shot, :, :, :] \r\n","            query_input   = data[val_N_way*val_N_shot: , :, :, :]\r\n","            # create the relative label (0 ~ N_way-1) for query data\r\n","            label_encoder = {target[i*val_N_shot] : i for i in range(val_N_way)}\r\n","            if torch.cuda.is_available():\r\n","                query_label = torch.cuda.LongTensor([label_encoder[class_name] for class_name in target[val_N_way*val_N_shot:]])\r\n","            else:\r\n","                query_label = torch.LongTensor([label_encoder[class_name] for class_name in target[val_N_way*val_N_shot:]])\r\n","\r\n","            support_encode = convnet(support_input) # extract the feature of support\r\n","            query_encode = convnet(query_input) # extract the feature of query\r\n","            support_proto = support_encode.view(val_N_way, val_N_shot, -1).mean(1)\r\n","            dists = euclidean_dist(query_encode, support_proto)\r\n","            p = softmax(-dists)\r\n","\r\n","            batch_loss = loss(p, query_label) # 計算 loss （注意 prediction 跟 label 必須同時在 CPU 或是 GPU 上）\r\n","            val_acc += np.mean(np.argmax(p.cpu().data.numpy(), axis=1) == query_label.cpu().data.numpy())\r\n","            val_loss += batch_loss.item()\r\n","\r\n","        if val_acc > best_val_acc:\r\n","            best_val_acc = val_acc\r\n","            torch.save(convnet.state_dict(), os.path.join(path, \"p1_model\", \"p1_convnet_{}way_{}shot_x.pkl\".format(str(train_N_way), str(train_N_shot))))\r\n","            print('save model')\r\n","\r\n","    print('epoch : {}, training epoch time: {:.4f} (sec)'.format(epoch, time.time()-training_epoch_time))\r\n","    print('train acc: {:.4f}, train loss: {:.5f}, val acc: {:.4f}, val loss: {:.5f}, best val acc: {:.4f}'.format(\r\n","        train_acc/len(train_loader), train_loss/len(train_loader), val_acc/len(val_loader), val_loss/len(val_loader), best_val_acc/len(val_loader)\r\n","    ))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZPGcn_Obv1m2"},"source":["# Testing"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vbR5ETvdz0oJ","executionInfo":{"status":"ok","timestamp":1608561202758,"user_tz":-480,"elapsed":959,"user":{"displayName":"GOD DP","photoUrl":"","userId":"07949532058692121683"}},"outputId":"e0e78268-def6-4fc2-848d-fb47d3cd81a2"},"source":["# set state\r\n","same_seeds(123) \r\n","\r\n","# set hyperparameters\r\n","val_N_way = 5\r\n","val_N_shot = 1    \r\n","val_N_query = 15\r\n","\r\n","# set data path\r\n","workspace_dir = \"./hw4_data\"\r\n","val_csv = os.path.join(workspace_dir, \"val.csv\")\r\n","val_data_dir = os.path.join(workspace_dir, \"val\")\r\n","valcase_csv = os.path.join(workspace_dir, \"val_testcase.csv\")\r\n","gt_csv = os.path.join(workspace_dir, \"val_testcase_gt.csv\")\r\n","output_csv = os.path.join(path, \"p1_output_{}way_{}shot.csv\".format(10, 1))\r\n","\r\n","# set dataset\r\n","val_dataset = MiniDataset(val_csv, val_data_dir, 'test')\r\n","print('finish dataset')\r\n","\r\n","val_loader = DataLoader(\r\n","        val_dataset, batch_size=val_N_way * (val_N_query + val_N_shot), num_workers=3, pin_memory=False, \r\n","        worker_init_fn=worker_init_fn, sampler=GeneratorSampler(valcase_csv, 'val'))\r\n","print('finish data_loader')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torchvision.__version__ = 0.5.0\n","torch.cuda.is_available() = True\n","finish dataset\n","finish data_loader\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pIEIUP84v3wI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608561253320,"user_tz":-480,"elapsed":40211,"user":{"displayName":"GOD DP","photoUrl":"","userId":"07949532058692121683"}},"outputId":"c4272401-b718-4a46-8a2b-eb180d586af6"},"source":["# set model\r\n","if torch.cuda.is_available():\r\n","    convnet = Convnet().cuda()\r\n","    convnet.load_state_dict(torch.load(os.path.join(path, \"p1_model\", \"p1_convnet_10way_1shot.pkl\")))\r\n","else:\r\n","    convnet = Convnet()\r\n","    convnet.load_state_dict(torch.load(os.path.join(path, \"p1_model\", \"p1_convnet_10way_1shot.pkl\"), map_location='cpu'))\r\n","\r\n","drop_list = ['class0_support0', 'class1_support0', 'class2_support0', 'class3_support0', 'class4_support0']\r\n","output_file = pd.read_csv(valcase_csv).copy().drop(columns=drop_list)\r\n","convnet.eval() \r\n","\r\n","with torch.no_grad():\r\n","    val_acc = 0.0\r\n","    val_loss = 0.0\r\n","    softmax = nn.Softmax(dim=1)\r\n","    loss = nn.CrossEntropyLoss() # 因為是 classification task，所以 loss 使用 CrossEntropyLoss\r\n","\r\n","    for i, (data, target) in enumerate(val_loader):\r\n","        if torch.cuda.is_available():\r\n","            data = data.cuda()\r\n","        # split data into support and query data\r\n","        support_input = data[:val_N_way*val_N_shot, :, :, :] \r\n","        query_input   = data[val_N_way*val_N_shot: , :, :, :]\r\n","        # create the relative label (0 ~ N_way-1) for query data\r\n","        label_encoder = {target[i*val_N_shot] : i for i in range(val_N_way)}\r\n","        if torch.cuda.is_available():\r\n","            query_label = torch.cuda.LongTensor([label_encoder[class_name] for class_name in target[val_N_way*val_N_shot:]])\r\n","        else:\r\n","            query_label = torch.LongTensor([label_encoder[class_name] for class_name in target[val_N_way*val_N_shot:]])\r\n","            \r\n","        support_encode = convnet(support_input) # extract the feature of support\r\n","        query_encode = convnet(query_input) # extract the feature of query\r\n","        support_proto = support_encode.view(val_N_way, val_N_shot, -1).mean(1)\r\n","        dists = euclidean_dist(query_encode, support_proto)\r\n","        p = softmax(-dists)\r\n","\r\n","        batch_loss = loss(p, query_label) # 計算 loss （注意 prediction 跟 label 必須同時在 CPU 或是 GPU 上）\r\n","        val_acc += np.mean(np.argmax(p.cpu().data.numpy(), axis=1) == query_label.cpu().data.numpy())\r\n","        val_loss += batch_loss.item()\r\n","\r\n","        for q in range(val_N_way*val_N_query):\r\n","            output_file.loc[i, 'query{}'.format(str(q))] = np.argmax(p.cpu().data.numpy(), axis=1)[q]\r\n","\r\n","print('val acc: {:.4f}, val loss: {:.5f}'.format(val_acc/len(val_loader), val_loss/len(val_loader)))\r\n","output_file = output_file.set_index(\"episode_id\")\r\n","output_file.to_csv(output_csv)\r\n","\r\n","# from google.colab import files\r\n","        \r\n","# # 存到本機端\r\n","# files.download(output_csv)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["val acc: 0.4985, val loss: 1.39408\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ocAzJAD0gvuN","executionInfo":{"status":"ok","timestamp":1608561265742,"user_tz":-480,"elapsed":1070,"user":{"displayName":"GOD DP","photoUrl":"","userId":"07949532058692121683"}},"outputId":"3796655c-6970-487b-ddb3-90b48c86ee68"},"source":["# read your prediction file\r\n","with open(output_csv, mode='r') as pred:\r\n","    reader = csv.reader(pred)\r\n","    next(reader, None)  # skip the headers\r\n","    pred_dict = {int(rows[0]): np.array(rows[1:]).astype(int) for rows in reader}\r\n","\r\n","# read ground truth data\r\n","with open(gt_csv, mode='r') as gt:\r\n","    reader = csv.reader(gt)\r\n","    next(reader, None)  # skip the headers\r\n","    gt_dict = {int(rows[0]): np.array(rows[1:]).astype(int) for rows in reader}\r\n","\r\n","if len(pred_dict) != len(gt_dict):\r\n","    sys.exit(\"Test case length mismatch.\")\r\n","\r\n","episodic_acc = []\r\n","for key, value in pred_dict.items():\r\n","    if key not in gt_dict:\r\n","        sys.exit(\"Episodic id mismatch: \\\"{}\\\" does not exist in the provided ground truth file.\".format(key))\r\n","\r\n","    episodic_acc.append((gt_dict[key] == value).mean().item())\r\n","\r\n","episodic_acc = np.array(episodic_acc)\r\n","mean = episodic_acc.mean()\r\n","std = episodic_acc.std()\r\n","\r\n","print('Accuracy: {:.2f} +- {:.2f} %'.format(mean * 100, 1.96 * std / (600)**(1/2) * 100))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy: 49.85 +- 0.84 %\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hvAYwH1ArE8-"},"source":["# Report (35%)"]},{"cell_type":"markdown","metadata":{"id":"AhYwM9BYsfbi"},"source":["In Problem 1-1, you will have to implement the prototypical network as your baseline model to perform 5-way 1-shot classification."]},{"cell_type":"markdown","metadata":{"id":"r1k-u9FwrKRm"},"source":["1. (11%) Describe the architecture & implementation details of your model. (Include but not limited to the number of training episodes, distance function, learning rate schedule, data augmentation, optimizer, and N-way K-shot setting for meta-train and meta-test phase)   \r\n","  **Please report the accuracy on validation set under 5-way 1-shot setting (during inference).**  \r\n","  **• The accuracy should be the same as your model performance in P.8.     \r\n","  • TAs will run your code to verify the performance.**"]},{"cell_type":"markdown","metadata":{"id":"Fjn93dpUt8Wg"},"source":["Hint   \r\n","The N-way K-shot setting in the meta-train phase may be different from the one in the meta-test phase. Your model may be trained better in larger ways (e.g., 10-way 1-shot setting in the meta-train phase and 5-way 1-shot setting in the meta-test phase)."]},{"cell_type":"code","metadata":{"id":"QqRqpMDrsFaP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608474656243,"user_tz":-480,"elapsed":732,"user":{"displayName":"曹林熹","photoUrl":"","userId":"17830086974482193998"}},"outputId":"8b5b2e87-9602-4fc8-f51b-573b44b3c72b"},"source":["print(Convnet())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Convnet(\n","  (encoder): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (6): ReLU()\n","    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (10): ReLU()\n","    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (12): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (14): ReLU()\n","    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"32f80Mp-sduZ"},"source":["For Problem 1-2 and 1-3, you will do some experiments about different distance function and different K shot settings."]},{"cell_type":"markdown","metadata":{"id":"ZvdXi1tWsFlX"},"source":["2. (12%) When meta-train and meta-test under the same 5-way 1-shot setting, please report and discuss the accuracy of the prototypical network using 3 different distance function **(i.e., Euclidean distance, cosine similarity and parametric function).** You should also describe how you design your parametric function.     \r\n","• Parametric: use a learnable model to measure distance between two features"]},{"cell_type":"code","metadata":{"id":"D91oTljOh70o"},"source":["# 1. Euclidean distance\r\n","# 2. cosine similarity\r\n","# 3. parametric function\r\n","\r\n","# create N-way-K-shot train_loader\r\n","def create_train_loader(traincase_csv):\r\n","    train_loader = DataLoader(\r\n","            train_dataset, batch_size=train_N_way * (train_N_query + train_N_shot), num_workers=3, pin_memory=False, \r\n","            worker_init_fn=worker_init_fn, sampler=GeneratorSampler(traincase_csv, 'train'))\r\n","    return train_loader\r\n","\r\n","# compute cosine similarity\r\n","def cosine_similarity(x, y):\r\n","    # x: N x D ex. (75, 1600)\r\n","    # y: M x D ex. (5, 1600)\r\n","    n = x.size(0) # ex. 75\r\n","    m = y.size(0) # ex. 5\r\n","    d = x.size(1) # ex. dim = 1600\r\n","    assert d == y.size(1)\r\n","\r\n","    cosine_similarity = nn.CosineSimilarity(dim=2, eps=1e-8)\r\n","    x = x.unsqueeze(1).expand(n, m, d)\r\n","    y = y.unsqueeze(0).expand(n, m, d)\r\n","\r\n","    return cosine_similarity(x, y)\r\n","\r\n","# set ParametricModel\r\n","class ParametricModel(nn.Module):\r\n","\r\n","    def __init__(self, in_channels = 1600, hid_channels = 64, out_channels = 1):\r\n","        super(ParametricModel, self).__init__()\r\n","\r\n","        self.function = nn.Sequential(\r\n","            \r\n","            nn.Linear(in_channels, hid_channels, bias=True),\r\n","            nn.BatchNorm1d(hid_channels),\r\n","            nn.ReLU(inplace=True),\r\n","            # [batch_size, hid_channels]\r\n","\r\n","            nn.Linear(hid_channels, hid_channels, bias=True),\r\n","            nn.BatchNorm1d(hid_channels),\r\n","            nn.ReLU(inplace=True),\r\n","            # [batch_size, hid_channels]\r\n","\r\n","            nn.Linear(hid_channels, out_channels, bias=True),\r\n","            # [batch_size, out_channels]    \r\n","\r\n","        )     \r\n","\r\n","    def forward(self, x, y):\r\n","        # x: N x D ex. (75, 1600)\r\n","        # y: M x D ex. (5, 1600)\r\n","        n = x.size(0) # ex. 75\r\n","        m = y.size(0) # ex. 5\r\n","        d = x.size(1) # ex. dim = 1600\r\n","        assert d == y.size(1)\r\n","\r\n","        x = x.unsqueeze(1).expand(n, m, d)\r\n","        y = y.unsqueeze(0).expand(n, m, d)\r\n","\r\n","        # print((x-y).shape)\r\n","        output = self.function((x-y).view(n*m, -1)) # [75*5, 1600]\r\n","        # print(output.shape)\r\n","        return output.view(n, -1) # [75, 5]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pPew5KAnsIag","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608554520603,"user_tz":-480,"elapsed":725,"user":{"displayName":"GOD DP","photoUrl":"","userId":"07949532058692121683"}},"outputId":"c49d352b-cf4b-42bb-d2de-d17606fc8388"},"source":["# set state\r\n","same_seeds(123) \r\n","\r\n","# set hyperparameters\r\n","train_N_way = 5\r\n","train_N_shot = 1    \r\n","train_N_query = 15\r\n","val_N_way = 5\r\n","val_N_shot = 1    \r\n","val_N_query = 15\r\n","num_episode = 100  \r\n","\r\n","# set data path\r\n","workspace_dir = \"./hw4_data\"\r\n","train_csv = os.path.join(workspace_dir, \"train.csv\")\r\n","train_data_dir = os.path.join(workspace_dir, \"train\")\r\n","val_csv = os.path.join(workspace_dir, \"val.csv\")\r\n","val_data_dir = os.path.join(workspace_dir, \"val\")\r\n","valcase_csv = os.path.join(workspace_dir, \"val_testcase.csv\")\r\n","gt_csv = os.path.join(workspace_dir, \"val_testcase_gt.csv\")\r\n","\r\n","# set dataset\r\n","train_dataset = MiniDataset(train_csv, train_data_dir, 'train')\r\n","val_dataset = MiniDataset(val_csv, val_data_dir, 'test')\r\n","print('finish dataset')\r\n","\r\n","val_loader = DataLoader(\r\n","        val_dataset, batch_size=val_N_way * (val_N_query + val_N_shot), num_workers=3, pin_memory=False, \r\n","        worker_init_fn=worker_init_fn, sampler=GeneratorSampler(valcase_csv, 'val'))\r\n","print('finish data_loader')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torchvision.__version__ = 0.5.0\n","torch.cuda.is_available() = True\n","finish dataset\n","finish data_loader\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5TIk11wqMvmk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608556378206,"user_tz":-480,"elapsed":1779675,"user":{"displayName":"GOD DP","photoUrl":"","userId":"07949532058692121683"}},"outputId":"3eeacae8-b6ec-4fdb-9e27-c049af72fcd3"},"source":["# set model\r\n","if torch.cuda.is_available():\r\n","    convnet = Convnet().cuda()\r\n","    # parametric_model = ParametricModel().cuda()\r\n","else:\r\n","    convnet = Convnet()\r\n","    # parametric_model = ParametricModel()\r\n","\r\n","loss = nn.CrossEntropyLoss() # 因為是 classification task，所以 loss 使用 CrossEntropyLoss\r\n","convnet_optimizer = torch.optim.Adam(convnet.parameters(), lr=0.001) # optimizer 使用 Adam \r\n","# parametric_model_optimizer = torch.optim.Adam(parametric_model.parameters(), lr=0.001) # optimizer 使用 Adam \r\n","softmax = nn.Softmax(dim=1)\r\n","\r\n","# set hyperparameters\r\n","num_epoch = 50\r\n","best_val_acc = 0.0\r\n","\r\n","for epoch in range(num_epoch):\r\n","    training_epoch_time = time.time()\r\n","    train_acc = 0.0\r\n","    train_loss = 0.0\r\n","    val_acc = 0.0\r\n","    val_loss = 0.0\r\n","    traincase_csv = create_traincase(N=train_N_way, K=train_N_shot, N_query=train_N_query, num_episode=num_episode, train_csv=train_csv)\r\n","    train_loader = create_train_loader(traincase_csv)\r\n","    print('finish train_loader')\r\n","\r\n","    convnet.train()\r\n","    # parametric_model.train() \r\n","\r\n","    # each batch represent one episode (support data + query data)\r\n","    for i, (data, target) in enumerate(train_loader):\r\n","        if torch.cuda.is_available():\r\n","            data = data.cuda()\r\n","        # split data into support and query data\r\n","        support_input = data[:train_N_way*train_N_shot, :, :, :] \r\n","        query_input   = data[train_N_way*train_N_shot: , :, :, :]\r\n","        # create the relative label (0 ~ N_way-1) for query data\r\n","        label_encoder = {target[i*train_N_shot] : i for i in range(train_N_way)}\r\n","        if torch.cuda.is_available():\r\n","            query_label = torch.cuda.LongTensor([label_encoder[class_name] for class_name in target[train_N_way*train_N_shot:]])\r\n","        else:\r\n","            query_label = torch.LongTensor([label_encoder[class_name] for class_name in target[train_N_way*train_N_shot:]])\r\n","\r\n","        convnet_optimizer.zero_grad() # 用 optimizer 將 convnet 參數的 gradient 歸零\r\n","        # parametric_model_optimizer.zero_grad()\r\n","\r\n","        support_encode = convnet(support_input) # extract the feature of support\r\n","        query_encode = convnet(query_input) # extract the feature of query\r\n","        support_proto = support_encode.view(train_N_way, train_N_shot, -1).mean(1)\r\n","        # dists = parametric_model(query_encode, support_proto)\r\n","        dists = cosine_similarity(query_encode, support_proto)\r\n","        # dists = euclidean_dist(query_encode, support_proto)\r\n","        # p = softmax(-dists)\r\n","        p = softmax(dists) # cos\r\n","\r\n","        batch_loss = loss(p, query_label) # 計算 loss （注意 prediction 跟 label 必須同時在 CPU 或是 GPU 上）\r\n","        batch_loss.backward() # 利用 back propagation 算出每個參數的 gradient\r\n","        convnet_optimizer.step() # 以 optimizer 用 gradient 更新參數值\r\n","        # parametric_model_optimizer.step()\r\n","\r\n","        train_acc += np.mean(np.argmax(p.cpu().data.numpy(), axis=1) == query_label.cpu().data.numpy())\r\n","        train_loss += batch_loss.item()\r\n","    \r\n","    convnet.eval()\r\n","    # parametric_model.eval() \r\n","\r\n","    with torch.no_grad():\r\n","        for i, (data, target) in enumerate(val_loader):\r\n","            if torch.cuda.is_available():\r\n","                data = data.cuda()\r\n","            # split data into support and query data\r\n","            support_input = data[:val_N_way*val_N_shot, :, :, :] \r\n","            query_input   = data[val_N_way*val_N_shot: , :, :, :]\r\n","            # create the relative label (0 ~ N_way-1) for query data\r\n","            label_encoder = {target[i*val_N_shot] : i for i in range(val_N_way)}\r\n","            if torch.cuda.is_available():\r\n","                query_label = torch.cuda.LongTensor([label_encoder[class_name] for class_name in target[val_N_way*val_N_shot:]])\r\n","            else:\r\n","                query_label = torch.LongTensor([label_encoder[class_name] for class_name in target[val_N_way*val_N_shot:]])\r\n","\r\n","            support_encode = convnet(support_input) # extract the feature of support\r\n","            query_encode = convnet(query_input) # extract the feature of query\r\n","            support_proto = support_encode.view(val_N_way, val_N_shot, -1).mean(1)\r\n","            # dists = parametric_model(query_encode, support_proto)\r\n","            dists = cosine_similarity(query_encode, support_proto)\r\n","            # dists = euclidean_dist(query_encode, support_proto)\r\n","            # p = softmax(-dists)\r\n","            p = softmax(dists) # cos\r\n","\r\n","            batch_loss = loss(p, query_label) # 計算 loss （注意 prediction 跟 label 必須同時在 CPU 或是 GPU 上）\r\n","            val_acc += np.mean(np.argmax(p.cpu().data.numpy(), axis=1) == query_label.cpu().data.numpy())\r\n","            val_loss += batch_loss.item()\r\n","\r\n","        if val_acc > best_val_acc :\r\n","            best_val_acc = val_acc\r\n","            torch.save(convnet.state_dict(), os.path.join(path, \"p1_model\", \"p1_convnet_cs.pkl\"))\r\n","            # torch.save(parametric_model.state_dict(), os.path.join(path, \"p1_model\", \"p1_parametric_model_pf.pkl\"))\r\n","            print('save model')\r\n","\r\n","    print('epoch : {}, training epoch time: {:.4f} (sec)'.format(epoch, time.time()-training_epoch_time))\r\n","    print('train acc: {:.4f}, train loss: {:.5f}, val acc: {:.4f}, val loss: {:.5f}, best val acc: {:.4f}'.format(\r\n","        train_acc/len(train_loader), train_loss/len(train_loader), val_acc/len(val_loader), val_loss/len(val_loader), best_val_acc/len(val_loader)\r\n","    ))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["finish train_loader\n","save model\n","epoch : 0, training epoch time: 39.3403 (sec)\n","train acc: 0.3013, train loss: 1.59452, val acc: 0.2770, val loss: 1.59996, best val acc: 0.2770\n","finish train_loader\n","save model\n","epoch : 1, training epoch time: 36.6852 (sec)\n","train acc: 0.2944, train loss: 1.59404, val acc: 0.2831, val loss: 1.59929, best val acc: 0.2831\n","finish train_loader\n","epoch : 2, training epoch time: 36.4840 (sec)\n","train acc: 0.3141, train loss: 1.59199, val acc: 0.2779, val loss: 1.59916, best val acc: 0.2831\n","finish train_loader\n","save model\n","epoch : 3, training epoch time: 35.7740 (sec)\n","train acc: 0.3165, train loss: 1.59245, val acc: 0.2942, val loss: 1.59658, best val acc: 0.2942\n","finish train_loader\n","epoch : 4, training epoch time: 35.5910 (sec)\n","train acc: 0.3304, train loss: 1.58896, val acc: 0.2800, val loss: 1.59762, best val acc: 0.2942\n","finish train_loader\n","epoch : 5, training epoch time: 35.8638 (sec)\n","train acc: 0.3059, train loss: 1.59150, val acc: 0.2907, val loss: 1.59760, best val acc: 0.2942\n","finish train_loader\n","epoch : 6, training epoch time: 35.7376 (sec)\n","train acc: 0.3343, train loss: 1.58668, val acc: 0.2866, val loss: 1.59809, best val acc: 0.2942\n","finish train_loader\n","epoch : 7, training epoch time: 35.6984 (sec)\n","train acc: 0.3181, train loss: 1.58985, val acc: 0.2688, val loss: 1.60029, best val acc: 0.2942\n","finish train_loader\n","epoch : 8, training epoch time: 36.1059 (sec)\n","train acc: 0.3295, train loss: 1.58947, val acc: 0.2887, val loss: 1.59706, best val acc: 0.2942\n","finish train_loader\n","epoch : 9, training epoch time: 35.8717 (sec)\n","train acc: 0.3156, train loss: 1.59161, val acc: 0.2886, val loss: 1.59796, best val acc: 0.2942\n","finish train_loader\n","epoch : 10, training epoch time: 35.8396 (sec)\n","train acc: 0.3175, train loss: 1.59080, val acc: 0.2794, val loss: 1.59789, best val acc: 0.2942\n","finish train_loader\n","epoch : 11, training epoch time: 35.9987 (sec)\n","train acc: 0.3368, train loss: 1.58789, val acc: 0.2739, val loss: 1.59897, best val acc: 0.2942\n","finish train_loader\n","epoch : 12, training epoch time: 35.6727 (sec)\n","train acc: 0.3437, train loss: 1.58570, val acc: 0.2758, val loss: 1.59873, best val acc: 0.2942\n","finish train_loader\n","epoch : 13, training epoch time: 36.0466 (sec)\n","train acc: 0.3365, train loss: 1.58604, val acc: 0.2814, val loss: 1.59742, best val acc: 0.2942\n","finish train_loader\n","epoch : 14, training epoch time: 35.4266 (sec)\n","train acc: 0.3231, train loss: 1.58993, val acc: 0.2771, val loss: 1.59887, best val acc: 0.2942\n","finish train_loader\n","epoch : 15, training epoch time: 35.7238 (sec)\n","train acc: 0.3571, train loss: 1.58405, val acc: 0.2923, val loss: 1.59585, best val acc: 0.2942\n","finish train_loader\n","epoch : 16, training epoch time: 35.3382 (sec)\n","train acc: 0.3383, train loss: 1.58636, val acc: 0.2766, val loss: 1.59945, best val acc: 0.2942\n","finish train_loader\n","epoch : 17, training epoch time: 35.3890 (sec)\n","train acc: 0.3317, train loss: 1.58864, val acc: 0.2757, val loss: 1.59892, best val acc: 0.2942\n","finish train_loader\n","epoch : 18, training epoch time: 35.6385 (sec)\n","train acc: 0.3421, train loss: 1.58675, val acc: 0.2925, val loss: 1.59601, best val acc: 0.2942\n","finish train_loader\n","epoch : 19, training epoch time: 35.2365 (sec)\n","train acc: 0.3351, train loss: 1.58695, val acc: 0.2856, val loss: 1.59762, best val acc: 0.2942\n","finish train_loader\n","epoch : 20, training epoch time: 35.4211 (sec)\n","train acc: 0.3451, train loss: 1.58479, val acc: 0.2879, val loss: 1.59886, best val acc: 0.2942\n","finish train_loader\n","epoch : 21, training epoch time: 35.2009 (sec)\n","train acc: 0.3275, train loss: 1.58824, val acc: 0.2676, val loss: 1.59997, best val acc: 0.2942\n","finish train_loader\n","epoch : 22, training epoch time: 35.3743 (sec)\n","train acc: 0.3352, train loss: 1.58648, val acc: 0.2938, val loss: 1.59661, best val acc: 0.2942\n","finish train_loader\n","epoch : 23, training epoch time: 35.4687 (sec)\n","train acc: 0.3333, train loss: 1.58698, val acc: 0.2831, val loss: 1.59736, best val acc: 0.2942\n","finish train_loader\n","epoch : 24, training epoch time: 35.6014 (sec)\n","train acc: 0.3235, train loss: 1.58829, val acc: 0.2844, val loss: 1.59700, best val acc: 0.2942\n","finish train_loader\n","epoch : 25, training epoch time: 35.4479 (sec)\n","train acc: 0.3275, train loss: 1.58826, val acc: 0.2706, val loss: 1.60025, best val acc: 0.2942\n","finish train_loader\n","epoch : 26, training epoch time: 35.2097 (sec)\n","train acc: 0.3327, train loss: 1.58745, val acc: 0.2938, val loss: 1.59711, best val acc: 0.2942\n","finish train_loader\n","epoch : 27, training epoch time: 35.6909 (sec)\n","train acc: 0.3355, train loss: 1.58765, val acc: 0.2857, val loss: 1.59747, best val acc: 0.2942\n","finish train_loader\n","epoch : 28, training epoch time: 35.4616 (sec)\n","train acc: 0.3380, train loss: 1.58627, val acc: 0.2938, val loss: 1.59649, best val acc: 0.2942\n","finish train_loader\n","epoch : 29, training epoch time: 35.4780 (sec)\n","train acc: 0.3448, train loss: 1.58671, val acc: 0.2913, val loss: 1.59601, best val acc: 0.2942\n","finish train_loader\n","epoch : 30, training epoch time: 35.1225 (sec)\n","train acc: 0.3365, train loss: 1.58635, val acc: 0.2859, val loss: 1.59776, best val acc: 0.2942\n","finish train_loader\n","epoch : 31, training epoch time: 35.5073 (sec)\n","train acc: 0.3527, train loss: 1.58361, val acc: 0.2898, val loss: 1.59690, best val acc: 0.2942\n","finish train_loader\n","epoch : 32, training epoch time: 35.0581 (sec)\n","train acc: 0.3483, train loss: 1.58467, val acc: 0.2937, val loss: 1.59510, best val acc: 0.2942\n","finish train_loader\n","save model\n","epoch : 33, training epoch time: 35.1604 (sec)\n","train acc: 0.3573, train loss: 1.58437, val acc: 0.3012, val loss: 1.59521, best val acc: 0.3012\n","finish train_loader\n","epoch : 34, training epoch time: 35.1411 (sec)\n","train acc: 0.3567, train loss: 1.58361, val acc: 0.2919, val loss: 1.59593, best val acc: 0.3012\n","finish train_loader\n","epoch : 35, training epoch time: 34.8952 (sec)\n","train acc: 0.3435, train loss: 1.58618, val acc: 0.2962, val loss: 1.59470, best val acc: 0.3012\n","finish train_loader\n","epoch : 36, training epoch time: 35.4119 (sec)\n","train acc: 0.3444, train loss: 1.58656, val acc: 0.2921, val loss: 1.59657, best val acc: 0.3012\n","finish train_loader\n","epoch : 37, training epoch time: 34.8842 (sec)\n","train acc: 0.3477, train loss: 1.58412, val acc: 0.2978, val loss: 1.59458, best val acc: 0.3012\n","finish train_loader\n","save model\n","epoch : 38, training epoch time: 35.1283 (sec)\n","train acc: 0.3572, train loss: 1.58329, val acc: 0.3034, val loss: 1.59420, best val acc: 0.3034\n","finish train_loader\n","epoch : 39, training epoch time: 34.9743 (sec)\n","train acc: 0.3428, train loss: 1.58500, val acc: 0.2915, val loss: 1.59619, best val acc: 0.3034\n","finish train_loader\n","save model\n","epoch : 40, training epoch time: 34.9877 (sec)\n","train acc: 0.3419, train loss: 1.58501, val acc: 0.3046, val loss: 1.59380, best val acc: 0.3046\n","finish train_loader\n","epoch : 41, training epoch time: 35.1594 (sec)\n","train acc: 0.3516, train loss: 1.58148, val acc: 0.2963, val loss: 1.59513, best val acc: 0.3046\n","finish train_loader\n","epoch : 42, training epoch time: 35.1113 (sec)\n","train acc: 0.3489, train loss: 1.58383, val acc: 0.2818, val loss: 1.59782, best val acc: 0.3046\n","finish train_loader\n","epoch : 43, training epoch time: 35.3994 (sec)\n","train acc: 0.3443, train loss: 1.58624, val acc: 0.2937, val loss: 1.59628, best val acc: 0.3046\n","finish train_loader\n","epoch : 44, training epoch time: 35.5193 (sec)\n","train acc: 0.3469, train loss: 1.58549, val acc: 0.2912, val loss: 1.59680, best val acc: 0.3046\n","finish train_loader\n","epoch : 45, training epoch time: 35.7925 (sec)\n","train acc: 0.3663, train loss: 1.58074, val acc: 0.2918, val loss: 1.59624, best val acc: 0.3046\n","finish train_loader\n","epoch : 46, training epoch time: 35.2814 (sec)\n","train acc: 0.3545, train loss: 1.58357, val acc: 0.2807, val loss: 1.59780, best val acc: 0.3046\n","finish train_loader\n","epoch : 47, training epoch time: 35.5852 (sec)\n","train acc: 0.3479, train loss: 1.58428, val acc: 0.2941, val loss: 1.59691, best val acc: 0.3046\n","finish train_loader\n","epoch : 48, training epoch time: 35.2144 (sec)\n","train acc: 0.3456, train loss: 1.58606, val acc: 0.2994, val loss: 1.59445, best val acc: 0.3046\n","finish train_loader\n","epoch : 49, training epoch time: 35.4021 (sec)\n","train acc: 0.3523, train loss: 1.58244, val acc: 0.2910, val loss: 1.59639, best val acc: 0.3046\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0Ub9XrdasIiG"},"source":["3. (12%) When meta-train and meta-test under the same 5-way K-shot setting, please report and compare the accuracy with different shots. (K=1, 5, 10)"]},{"cell_type":"code","metadata":{"id":"8EgRHmaUMdqQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608640494844,"user_tz":-480,"elapsed":10000,"user":{"displayName":"曹林熹","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1rp1WgUEEdLYBSWWUtH2FPvqx3Hdazi01GHGD=s64","userId":"06338317211672502600"}},"outputId":"c48d79f2-9b9d-4deb-d716-1517cd74f973"},"source":["# create N-way-K-shot train_loader\r\n","def create_train_loader(traincase_csv):\r\n","    train_loader = DataLoader(\r\n","            train_dataset, batch_size=train_N_way * (train_N_query + train_N_shot), num_workers=3, pin_memory=False, \r\n","            worker_init_fn=worker_init_fn, sampler=GeneratorSampler(traincase_csv, 'train'))\r\n","    return train_loader\r\n","\r\n","# set state\r\n","same_seeds(123) \r\n","\r\n","# set hyperparameters\r\n","train_N_way = 5\r\n","train_N_shot = 10 \r\n","train_N_query = 15\r\n","val_N_way = 5\r\n","val_N_shot = 10    \r\n","val_N_query = 15\r\n","num_episode = 400  \r\n","\r\n","# set data path\r\n","workspace_dir = \"./hw4_data\"\r\n","train_csv = os.path.join(workspace_dir, \"train.csv\")\r\n","train_data_dir = os.path.join(workspace_dir, \"train\")\r\n","val_csv = os.path.join(workspace_dir, \"val.csv\")\r\n","val_data_dir = os.path.join(workspace_dir, \"val\")\r\n","gt_csv = os.path.join(workspace_dir, \"val_testcase_gt.csv\")\r\n","\r\n","# set dataset\r\n","train_dataset = MiniDataset(train_csv, train_data_dir, 'train')\r\n","val_dataset = MiniDataset(val_csv, val_data_dir, 'test')\r\n","print('finish dataset')\r\n","\r\n","# create val_N_way valcase_csv\r\n","valcase_csv = create_traincase(N=val_N_way, K=val_N_shot, N_query=val_N_query, num_episode=num_episode, train_csv=val_csv)\r\n","val_loader = DataLoader(\r\n","        val_dataset, batch_size=val_N_way * (val_N_query + val_N_shot), num_workers=3, pin_memory=False, \r\n","        worker_init_fn=worker_init_fn, sampler=GeneratorSampler(valcase_csv, 'train'))\r\n","print('finish data_loader')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torchvision.__version__ = 0.8.1+cu101\n","torch.cuda.is_available() = True\n","finish dataset\n","finish data_loader\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NYgED4Lf0Pje","executionInfo":{"status":"ok","timestamp":1608482688237,"user_tz":-480,"elapsed":3325481,"user":{"displayName":"GOD DP","photoUrl":"","userId":"07949532058692121683"}},"outputId":"c34abcb4-e95b-4bcb-e6d0-ef1bd28f9acc"},"source":["# set model\r\n","if torch.cuda.is_available():\r\n","    convnet = Convnet().cuda()\r\n","else:\r\n","    convnet = Convnet()\r\n","\r\n","loss = nn.CrossEntropyLoss() # 因為是 classification task，所以 loss 使用 CrossEntropyLoss\r\n","convnet_optimizer = torch.optim.Adam(convnet.parameters(), lr=0.001) # optimizer 使用 Adam \r\n","softmax = nn.Softmax(dim=1)\r\n","\r\n","# set hyperparameters\r\n","num_epoch = 50\r\n","best_val_acc = 0.0\r\n","\r\n","for epoch in range(num_epoch):\r\n","    training_epoch_time = time.time()\r\n","    train_acc = 0.0\r\n","    train_loss = 0.0\r\n","    val_acc = 0.0\r\n","    val_loss = 0.0\r\n","    traincase_csv = create_traincase(N=train_N_way, K=train_N_shot, N_query=train_N_query, num_episode=num_episode, train_csv=train_csv)\r\n","    train_loader = create_train_loader(traincase_csv)\r\n","    print('finish train_loader')\r\n","\r\n","    convnet.train() \r\n","\r\n","    # each batch represent one episode (support data + query data)\r\n","    for i, (data, target) in enumerate(train_loader):\r\n","        if torch.cuda.is_available():\r\n","            data = data.cuda()\r\n","        # split data into support and query data\r\n","        support_input = data[:train_N_way*train_N_shot, :, :, :] \r\n","        query_input   = data[train_N_way*train_N_shot: , :, :, :]\r\n","        # create the relative label (0 ~ N_way-1) for query data\r\n","        label_encoder = {target[i*train_N_shot] : i for i in range(train_N_way)}\r\n","        if torch.cuda.is_available():\r\n","            query_label = torch.cuda.LongTensor([label_encoder[class_name] for class_name in target[train_N_way*train_N_shot:]])\r\n","        else:\r\n","            query_label = torch.LongTensor([label_encoder[class_name] for class_name in target[train_N_way*train_N_shot:]])\r\n","\r\n","        convnet_optimizer.zero_grad() # 用 optimizer 將 convnet 參數的 gradient 歸零\r\n","\r\n","        support_encode = convnet(support_input) # extract the feature of support\r\n","        query_encode = convnet(query_input) # extract the feature of query\r\n","        support_proto = support_encode.view(train_N_way, train_N_shot, -1).mean(1)\r\n","        dists = euclidean_dist(query_encode, support_proto) \r\n","        p = softmax(-dists)\r\n","\r\n","        batch_loss = loss(p, query_label) # 計算 loss （注意 prediction 跟 label 必須同時在 CPU 或是 GPU 上）\r\n","        batch_loss.backward() # 利用 back propagation 算出每個參數的 gradient\r\n","        convnet_optimizer.step() # 以 optimizer 用 gradient 更新參數值\r\n","\r\n","        train_acc += np.mean(np.argmax(p.cpu().data.numpy(), axis=1) == query_label.cpu().data.numpy())\r\n","        train_loss += batch_loss.item()\r\n","    \r\n","    convnet.eval()  \r\n","\r\n","    with torch.no_grad():\r\n","        for i, (data, target) in enumerate(val_loader):\r\n","            if torch.cuda.is_available():\r\n","                data = data.cuda()\r\n","            # split data into support and query data\r\n","            support_input = data[:val_N_way*val_N_shot, :, :, :] \r\n","            query_input   = data[val_N_way*val_N_shot: , :, :, :]\r\n","            # create the relative label (0 ~ N_way-1) for query data\r\n","            label_encoder = {target[i*val_N_shot] : i for i in range(val_N_way)}\r\n","            if torch.cuda.is_available():\r\n","                query_label = torch.cuda.LongTensor([label_encoder[class_name] for class_name in target[val_N_way*val_N_shot:]])\r\n","            else:\r\n","                query_label = torch.LongTensor([label_encoder[class_name] for class_name in target[val_N_way*val_N_shot:]])\r\n","\r\n","            support_encode = convnet(support_input) # extract the feature of support\r\n","            query_encode = convnet(query_input) # extract the feature of query\r\n","            support_proto = support_encode.view(val_N_way, val_N_shot, -1).mean(1)\r\n","            dists = euclidean_dist(query_encode, support_proto)\r\n","            p = softmax(-dists)\r\n","\r\n","            batch_loss = loss(p, query_label) # 計算 loss （注意 prediction 跟 label 必須同時在 CPU 或是 GPU 上）\r\n","            val_acc += np.mean(np.argmax(p.cpu().data.numpy(), axis=1) == query_label.cpu().data.numpy())\r\n","            val_loss += batch_loss.item()\r\n","\r\n","        if val_acc > best_val_acc:\r\n","            best_val_acc = val_acc\r\n","            torch.save(convnet.state_dict(), os.path.join(path, \"p1_model\", \"p1_convnet_5way_5shot.pkl\"))\r\n","            print('save model')\r\n","\r\n","    print('epoch : {}, training epoch time: {:.4f} (sec)'.format(epoch, time.time()-training_epoch_time))\r\n","    print('train acc: {:.4f}, train loss: {:.5f}, val acc: {:.4f}, val loss: {:.5f}, best val acc: {:.4f}'.format(\r\n","        train_acc/len(train_loader), train_loss/len(train_loader), val_acc/len(val_loader), val_loss/len(val_loader), best_val_acc/len(val_loader)\r\n","    ))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["finish train_loader\n","save model\n","epoch : 0, training epoch time: 69.6419 (sec)\n","train acc: 0.3408, train loss: 1.56339, val acc: 0.3257, val loss: 1.57769, best val acc: 0.3257\n","finish train_loader\n","save model\n","epoch : 1, training epoch time: 66.4518 (sec)\n","train acc: 0.3291, train loss: 1.57474, val acc: 0.3283, val loss: 1.57561, best val acc: 0.3283\n","finish train_loader\n","save model\n","epoch : 2, training epoch time: 66.3752 (sec)\n","train acc: 0.3645, train loss: 1.53979, val acc: 0.3459, val loss: 1.55808, best val acc: 0.3459\n","finish train_loader\n","epoch : 3, training epoch time: 66.6321 (sec)\n","train acc: 0.3740, train loss: 1.52972, val acc: 0.3358, val loss: 1.56842, best val acc: 0.3459\n","finish train_loader\n","epoch : 4, training epoch time: 66.1345 (sec)\n","train acc: 0.3748, train loss: 1.52917, val acc: 0.3226, val loss: 1.58137, best val acc: 0.3459\n","finish train_loader\n","epoch : 5, training epoch time: 66.0348 (sec)\n","train acc: 0.3797, train loss: 1.52426, val acc: 0.3108, val loss: 1.59283, best val acc: 0.3459\n","finish train_loader\n","epoch : 6, training epoch time: 66.5507 (sec)\n","train acc: 0.3888, train loss: 1.51481, val acc: 0.3353, val loss: 1.56844, best val acc: 0.3459\n","finish train_loader\n","save model\n","epoch : 7, training epoch time: 66.4469 (sec)\n","train acc: 0.3989, train loss: 1.50500, val acc: 0.3564, val loss: 1.54748, best val acc: 0.3564\n","finish train_loader\n","save model\n","epoch : 8, training epoch time: 66.8052 (sec)\n","train acc: 0.3963, train loss: 1.50786, val acc: 0.3592, val loss: 1.54468, best val acc: 0.3592\n","finish train_loader\n","epoch : 9, training epoch time: 65.9678 (sec)\n","train acc: 0.4006, train loss: 1.50350, val acc: 0.3454, val loss: 1.55865, best val acc: 0.3592\n","finish train_loader\n","save model\n","epoch : 10, training epoch time: 69.5303 (sec)\n","train acc: 0.3945, train loss: 1.50952, val acc: 0.3681, val loss: 1.53600, best val acc: 0.3681\n","finish train_loader\n","epoch : 11, training epoch time: 69.1694 (sec)\n","train acc: 0.4031, train loss: 1.50077, val acc: 0.3562, val loss: 1.54781, best val acc: 0.3681\n","finish train_loader\n","epoch : 12, training epoch time: 66.6716 (sec)\n","train acc: 0.3989, train loss: 1.50536, val acc: 0.3674, val loss: 1.53650, best val acc: 0.3681\n","finish train_loader\n","save model\n","epoch : 13, training epoch time: 66.0881 (sec)\n","train acc: 0.4116, train loss: 1.49250, val acc: 0.3713, val loss: 1.53299, best val acc: 0.3713\n","finish train_loader\n","epoch : 14, training epoch time: 66.8669 (sec)\n","train acc: 0.4017, train loss: 1.50257, val acc: 0.3672, val loss: 1.53687, best val acc: 0.3713\n","finish train_loader\n","save model\n","epoch : 15, training epoch time: 66.6029 (sec)\n","train acc: 0.4139, train loss: 1.49019, val acc: 0.3738, val loss: 1.53024, best val acc: 0.3738\n","finish train_loader\n","epoch : 16, training epoch time: 66.6090 (sec)\n","train acc: 0.4148, train loss: 1.48934, val acc: 0.3637, val loss: 1.54035, best val acc: 0.3738\n","finish train_loader\n","epoch : 17, training epoch time: 66.6611 (sec)\n","train acc: 0.4145, train loss: 1.48953, val acc: 0.3688, val loss: 1.53521, best val acc: 0.3738\n","finish train_loader\n","epoch : 18, training epoch time: 66.3814 (sec)\n","train acc: 0.3875, train loss: 1.51702, val acc: 0.3678, val loss: 1.53614, best val acc: 0.3738\n","finish train_loader\n","epoch : 19, training epoch time: 66.6015 (sec)\n","train acc: 0.4098, train loss: 1.49431, val acc: 0.3604, val loss: 1.54369, best val acc: 0.3738\n","finish train_loader\n","save model\n","epoch : 20, training epoch time: 66.4665 (sec)\n","train acc: 0.4244, train loss: 1.47944, val acc: 0.3803, val loss: 1.52404, best val acc: 0.3803\n","finish train_loader\n","epoch : 21, training epoch time: 66.3189 (sec)\n","train acc: 0.4150, train loss: 1.48902, val acc: 0.3676, val loss: 1.53621, best val acc: 0.3803\n","finish train_loader\n","epoch : 22, training epoch time: 66.2185 (sec)\n","train acc: 0.4150, train loss: 1.48876, val acc: 0.3793, val loss: 1.52469, best val acc: 0.3803\n","finish train_loader\n","epoch : 23, training epoch time: 66.5913 (sec)\n","train acc: 0.4331, train loss: 1.47124, val acc: 0.3749, val loss: 1.52921, best val acc: 0.3803\n","finish train_loader\n","epoch : 24, training epoch time: 66.2365 (sec)\n","train acc: 0.4246, train loss: 1.47954, val acc: 0.3798, val loss: 1.52410, best val acc: 0.3803\n","finish train_loader\n","save model\n","epoch : 25, training epoch time: 66.2338 (sec)\n","train acc: 0.4303, train loss: 1.47391, val acc: 0.3834, val loss: 1.52016, best val acc: 0.3834\n","finish train_loader\n","epoch : 26, training epoch time: 65.8634 (sec)\n","train acc: 0.4281, train loss: 1.47609, val acc: 0.3792, val loss: 1.52497, best val acc: 0.3834\n","finish train_loader\n","epoch : 27, training epoch time: 65.8312 (sec)\n","train acc: 0.4337, train loss: 1.47051, val acc: 0.3833, val loss: 1.52070, best val acc: 0.3834\n","finish train_loader\n","epoch : 28, training epoch time: 66.1917 (sec)\n","train acc: 0.4276, train loss: 1.47659, val acc: 0.3639, val loss: 1.54006, best val acc: 0.3834\n","finish train_loader\n","save model\n","epoch : 29, training epoch time: 66.5275 (sec)\n","train acc: 0.4245, train loss: 1.47979, val acc: 0.3943, val loss: 1.50959, best val acc: 0.3943\n","finish train_loader\n","epoch : 30, training epoch time: 66.1319 (sec)\n","train acc: 0.4284, train loss: 1.47566, val acc: 0.3840, val loss: 1.52019, best val acc: 0.3943\n","finish train_loader\n","save model\n","epoch : 31, training epoch time: 66.3305 (sec)\n","train acc: 0.4415, train loss: 1.46244, val acc: 0.4067, val loss: 1.49738, best val acc: 0.4067\n","finish train_loader\n","save model\n","epoch : 32, training epoch time: 66.2203 (sec)\n","train acc: 0.4447, train loss: 1.45929, val acc: 0.4072, val loss: 1.49693, best val acc: 0.4072\n","finish train_loader\n","epoch : 33, training epoch time: 65.8721 (sec)\n","train acc: 0.4557, train loss: 1.44870, val acc: 0.4051, val loss: 1.49921, best val acc: 0.4072\n","finish train_loader\n","save model\n","epoch : 34, training epoch time: 66.0946 (sec)\n","train acc: 0.4700, train loss: 1.43409, val acc: 0.4175, val loss: 1.48668, best val acc: 0.4175\n","finish train_loader\n","epoch : 35, training epoch time: 66.4093 (sec)\n","train acc: 0.4651, train loss: 1.43897, val acc: 0.4128, val loss: 1.49157, best val acc: 0.4175\n","finish train_loader\n","epoch : 36, training epoch time: 65.9872 (sec)\n","train acc: 0.4542, train loss: 1.44969, val acc: 0.4025, val loss: 1.50158, best val acc: 0.4175\n","finish train_loader\n","epoch : 37, training epoch time: 66.3266 (sec)\n","train acc: 0.4666, train loss: 1.43737, val acc: 0.4135, val loss: 1.49034, best val acc: 0.4175\n","finish train_loader\n","epoch : 38, training epoch time: 66.0338 (sec)\n","train acc: 0.4588, train loss: 1.44558, val acc: 0.4011, val loss: 1.50266, best val acc: 0.4175\n","finish train_loader\n","epoch : 39, training epoch time: 66.4308 (sec)\n","train acc: 0.4548, train loss: 1.44925, val acc: 0.4147, val loss: 1.48927, best val acc: 0.4175\n","finish train_loader\n","epoch : 40, training epoch time: 66.1679 (sec)\n","train acc: 0.4740, train loss: 1.42995, val acc: 0.4153, val loss: 1.48898, best val acc: 0.4175\n","finish train_loader\n","save model\n","epoch : 41, training epoch time: 66.2369 (sec)\n","train acc: 0.4758, train loss: 1.42815, val acc: 0.4223, val loss: 1.48183, best val acc: 0.4223\n","finish train_loader\n","epoch : 42, training epoch time: 66.6155 (sec)\n","train acc: 0.4687, train loss: 1.43551, val acc: 0.3999, val loss: 1.50410, best val acc: 0.4223\n","finish train_loader\n","save model\n","epoch : 43, training epoch time: 66.3810 (sec)\n","train acc: 0.4720, train loss: 1.43243, val acc: 0.4236, val loss: 1.48043, best val acc: 0.4236\n","finish train_loader\n","save model\n","epoch : 44, training epoch time: 66.1144 (sec)\n","train acc: 0.4772, train loss: 1.42711, val acc: 0.4351, val loss: 1.46912, best val acc: 0.4351\n","finish train_loader\n","epoch : 45, training epoch time: 65.8344 (sec)\n","train acc: 0.4710, train loss: 1.43318, val acc: 0.4230, val loss: 1.48069, best val acc: 0.4351\n","finish train_loader\n","epoch : 46, training epoch time: 66.1558 (sec)\n","train acc: 0.4757, train loss: 1.42849, val acc: 0.4211, val loss: 1.48282, best val acc: 0.4351\n","finish train_loader\n","epoch : 47, training epoch time: 65.8618 (sec)\n","train acc: 0.4788, train loss: 1.42546, val acc: 0.4131, val loss: 1.49068, best val acc: 0.4351\n","finish train_loader\n","epoch : 48, training epoch time: 66.4494 (sec)\n","train acc: 0.4721, train loss: 1.43213, val acc: 0.4107, val loss: 1.49337, best val acc: 0.4351\n","finish train_loader\n","epoch : 49, training epoch time: 65.8593 (sec)\n","train acc: 0.4733, train loss: 1.43067, val acc: 0.4216, val loss: 1.48273, best val acc: 0.4351\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ME4zkWG0sW9w"},"source":["**Hint    \r\n","In order to reduce the training time, you may use a model simpler than that in Problem 1-1\r\n","for these two subproblems. For example, you can train the model with less training epochs.**"]}]}