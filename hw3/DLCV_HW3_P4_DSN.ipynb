{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DLCV_HW3_P4_DSN.ipynb","provenance":[{"file_id":"1RDrSk0bQcrlmTNfmelYLffs7GOnMzF9H","timestamp":1605112170498},{"file_id":"1nlFbu_i1mlIEjWl--B4-VSD0_JNHkIzN","timestamp":1605111862798},{"file_id":"1M5m6Kws-4Qb8AhziV1hPV0NNHS57nYhh","timestamp":1605111534626},{"file_id":"1wOwIH-17CAbGZN11e3g-bBefPVY7CNXu","timestamp":1605110875937},{"file_id":"1zDZIQUj3WJ5EeDXcS05xoZ8LTgA2kA0l","timestamp":1604660737258}],"collapsed_sections":["GTTVP5YU-v2M","ywOrm8CT_ZUz","H_zVMpfe_nNM"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"VZwgyCrff2uG"},"source":["# **Homework #3_P4**"]},{"cell_type":"markdown","metadata":{"id":"YGmW50agkRQ5"},"source":["## **Problem 4: Improved UDA model (35%)** \n","### **Task Definition**\n","In this problem, you need to implement an improved model on digits datasets\n","(USPS, MNIST-M and SVHN) and consider the following 3 scenarios: (Source\n","domain → Target domain)    \n","USPS → MNIST-M, MNIST-M → SVHN, SVHN → USPS     \n","Note that during training your improved UDA model, we utilize the images andlabels of source domain, and only images (without labels) of target domain.\n","### **Grading**\n","• If your accuracy of Problem 3-2 does not pass the baseline accuracy,\n","you only get 3 points in this sub-problem.    \n","*   Pass the baseline in one scenario: 3+3 points, two: 3+5 points, three: 3+7 points\n","\n","• Baseline score for DANN:   \n","*   USPS → MNIST-M: 40% \n","*   MNIST-M → SVHN: 40%\n","*   SVHN → USPS: 40%\n","\n","\n","• Your accuracy of problem 4-1 should surpass the accuracy reported in\n","problem 3-2. If not, you only get 6 points in this sub-problem.    \n","*   Improve in one scenario: 6+4 points, two: 6+7 points, three: 6+10 points"]},{"cell_type":"code","metadata":{"id":"adAwLz2bnSD_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606635577362,"user_tz":-480,"elapsed":63527,"user":{"displayName":"GOD DP","photoUrl":"","userId":"07949532058692121683"}},"outputId":"a4e3bd70-db28-4296-b008-eef96bc463de"},"source":["# connect to drive\n","from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)\n","\n","# you can define your own path to save data\n","path = 'drive/My Drive/senior_1/DLCV/HW/hw3'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0YXNXC8vu1Z4"},"source":["!gdown --id '1Cz5eLSP7QRMkO0PqxZLldJ36nK6EWHR8' --output hw3_data.zip # 下載資料集\n","!unzip hw3_data.zip # 解壓縮\n","'''\n","1.  hw3_data/digits/mnistm/\n","      # num of data: 60,000 (training) / 10,000 (testing) # num of classes: 10 (0~9) # Image size: 28*28*3\n","      train/images.png\n","      test/images.png\n","      train.csv\n","      test.csv\n","2.  hw3_data/digits/svhn/\n","      # num of data: 73,257 (training) / 26,032 (testing) # num of classes: 10 (0~9) # Image size: 28*28*3\n","      train/images.png\n","      test/images.png\n","      train.csv\n","      test.csv\n","3.  hw3_data/digits/usps/\n","      # num of data: 7,291 (training) / 2,007 (testing) # num of classes: 10 (0~9) # Image size: 28*28*1\n","      train/images.png  \n","      test/images.png  \n","      train.csv\n","      test.csv\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gCJYPIW6Hxkn"},"source":["# set packages\n","!pip3 install certifi==2020.6.20\n","!pip3 install cycler==0.10.0\n","!pip3 install joblib==0.17.0\n","!pip3 install kiwisolver==1.2.0\n","!pip3 install matplotlib==3.3.2\n","!pip3 install numpy==1.18.1\n","!pip3 install pandas==1.1.3\n","!pip3 install Pillow==8.0.0\n","!pip3 install pyparsing==2.4.7\n","!pip3 install python-dateutil==2.8.1\n","!pip3 install pytz==2020.1\n","!pip3 install scikit-learn==0.21.3\n","!pip3 install scipy==1.2.1\n","!pip3 install six==1.15.0\n","!pip3 install torch==1.4.0\n","!pip3 install torchvision==0.5.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pc-8lzpZvBYY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606621595271,"user_tz":-480,"elapsed":1308,"user":{"displayName":"曹林熹","photoUrl":"","userId":"17830086974482193998"}},"outputId":"0cd2e652-eb6e-4595-ac61-84c82e1284db"},"source":["# Import 需要的套件\n","import os\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torchvision.models as models\n","import torchvision\n","from torch.utils.data import DataLoader, Dataset\n","import torchvision.transforms as transforms\n","import time\n","import pandas as pd\n","import random\n","import scipy.misc\n","import argparse\n","import imageio\n","from torch.autograd import Variable\n","from torch.optim import Adam, AdamW\n","import csv\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn import manifold\n","from torch.autograd import Function\n","\n","# 固定隨機種子\n","def same_seeds(seed):\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n","    np.random.seed(seed)  # Numpy module.\n","    random.seed(seed)  # Python random module.\n","    torch.backends.cudnn.benchmark = False\n","    torch.backends.cudnn.deterministic = True\n","    print(\"torchvision.__version__ =\", torchvision.__version__)\n","    print(\"torch.cuda.is_available() =\", torch.cuda.is_available())\n","\n","same_seeds(0)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torchvision.__version__ = 0.5.0\n","torch.cuda.is_available() = True\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-BYvw0AuvOhW"},"source":["#Read image"]},{"cell_type":"code","metadata":{"id":"CIqOBhcjvQRl"},"source":["def sortfile(path):\n","    index = []\n","    image_dir = sorted(os.listdir(path)) # 把圖檔按照編號排列\n","    for i, file in enumerate(image_dir):\n","        index.append([file, int(file.replace('.png', ''))])\n","    index = sorted(index, key = lambda s: s[1])\n","    return index\n","\n","def readfile(path, index, mode):\n","    x = np.zeros((len(index), 28, 28, 3), dtype=np.uint8)\n","    y = np.zeros((len(index)), dtype=np.uint8)\n","    pd_y = pd.read_csv(os.path.join(path, mode + \".csv\"))\n","    for i, file in enumerate(index):\n","        img = imageio.imread(os.path.join(os.path.join(path, mode), file[0]))\n","        if 'usps' in path:\n","            temp_x = img.reshape(28, 28, 1) # expand dim\n","            x[i, :, :] = np.concatenate((temp_x, temp_x, temp_x), axis = 2)\n","        else:\n","            x[i, :, :] = img \n","        y[i] = pd_y['label'][i] \n","    return x, y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"slUYUiRlvSV1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606621654698,"user_tz":-480,"elapsed":55817,"user":{"displayName":"曹林熹","photoUrl":"","userId":"17830086974482193998"}},"outputId":"72c5140b-7d81-498d-eaf0-bb150450d654"},"source":["# 分別將 training set、testing set 用 sortfile, readfile 函式讀進來\n","workspace_dir = './hw3_data/digits'\n","digits_data_list = ['mnistm', 'svhn', 'usps']\n","\n","for index in digits_data_list:\n","    print(\"Reading \" + index + \" data\")\n","    split_ratio = 0.2\n","    train_index = sortfile(os.path.join(workspace_dir, os.path.join(index, \"train\")))\n","    test_index = sortfile(os.path.join(workspace_dir, os.path.join(index, \"test\")))\n","    if index == 'mnistm':\n","        mnistm_train_x, mnistm_train_y = readfile(os.path.join(workspace_dir, index), train_index, \"train\")\n","        # split train / val, ratio = split_ratio\n","        mnistm_train_x, mnistm_val_x, mnistm_train_y, mnistm_val_y = train_test_split(mnistm_train_x, mnistm_train_y, test_size = split_ratio, random_state = 3)\n","        mnistm_test_x, mnistm_test_y = readfile(os.path.join(workspace_dir, index), test_index, \"test\")\n","        mnistm_test_index = pd.DataFrame(test_index)[0].values.tolist()\n","    elif index == 'svhn':\n","        svhn_train_x, svhn_train_y = readfile(os.path.join(workspace_dir, index), train_index, \"train\")\n","        # split train / val, ratio = split_ratio\n","        svhn_train_x, svhn_val_x, svhn_train_y, svhn_val_y = train_test_split(svhn_train_x, svhn_train_y, test_size = split_ratio, random_state = 3) \n","        svhn_test_x, svhn_test_y = readfile(os.path.join(workspace_dir, index), test_index, \"test\")\n","        svhn_test_index = pd.DataFrame(test_index)[0].values.tolist()  \n","    else:\n","        usps_train_x, usps_train_y = readfile(os.path.join(workspace_dir, index), train_index, \"train\")\n","        # split train / val, ratio = split_ratio\n","        usps_train_x,usps_val_x, usps_train_y, usps_val_y = train_test_split(usps_train_x, usps_train_y, test_size = split_ratio, random_state = 3)\n","        usps_test_x, usps_test_y = readfile(os.path.join(workspace_dir, index), test_index, \"test\") \n","        usps_test_index = pd.DataFrame(test_index)[0].values.tolist()\n","    print(\"Size of {} training data = {}\".format(index, round(len(train_index)*(1-split_ratio))))\n","    print(\"Size of {} validation data = {}\".format(index, round(len(train_index)*split_ratio)))\n","    print(\"Size of {} testing data = {}\".format(index, round(len(test_index))))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Reading mnistm data\n","Size of mnistm training data = 48000\n","Size of mnistm validation data = 12000\n","Size of mnistm testing data = 10000\n","Reading svhn data\n","Size of svhn training data = 58606\n","Size of svhn validation data = 14651\n","Size of svhn testing data = 26032\n","Reading usps data\n","Size of usps training data = 5833\n","Size of usps validation data = 1458\n","Size of usps testing data = 2007\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Wawxx_zlMY14"},"source":["# Dataset\n","在 PyTorch 中，我們可以利用 torch.utils.data 的 Dataset 及 DataLoader 來\"包裝\" data，使後續的 training 及 testing 更為方便。\n","\n","Dataset 需要 overload 兩個函數：\\_\\_len\\_\\_ 及 \\_\\_getitem\\_\\_\n","\n","\\_\\_len\\_\\_ 必須要回傳 dataset 的大小，而 \\_\\_getitem\\_\\_ 則定義了當程式利用 [ ] 取值時，dataset 應該要怎麼回傳資料。\n","\n","實際上我們並不會直接使用到這兩個函數，但是使用 DataLoader 在 enumerate Dataset 時會使用到，沒有實做的話會在程式運行階段出現 error。\n"]},{"cell_type":"code","metadata":{"id":"7eHp0XHGMcJx"},"source":["# training 時需做 data augmentation\n","train_transform = transforms.Compose([\n","    transforms.ToPILImage(), # 轉成 python 圖片\n","    transforms.ToTensor(), # 將圖片轉成 Tensor，並把數值 normalize 到 [0,1] (data normalization) ps. Tensor 為多維張量\n","    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)) # normalize\n","])\n","\n","# testing 時不需做 data augmentation\n","test_transform = transforms.Compose([\n","    transforms.ToPILImage(),                                    \n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)) # normalize\n","])\n","\n","class ImgDataset(Dataset):\n","    def __init__(self, x, y=None, transform=None): # transform 自己決定\n","        self.x = x\n","        # label is required to be a LongTensor\n","        self.y = y\n","        if y is not None:\n","            self.y = torch.LongTensor(y)\n","        self.transform = transform\n","    def __len__(self):\n","        return len(self.x)\n","    def __getitem__(self, index):\n","        X = self.x[index]\n","        if self.transform is not None:\n","            X = self.transform(X)\n","        if self.y is not None:\n","            Y = self.y[index]\n","            return X, Y\n","        else:\n","            return X"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RwtuJdrOMgJK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606621655684,"user_tz":-480,"elapsed":976,"user":{"displayName":"曹林熹","photoUrl":"","userId":"17830086974482193998"}},"outputId":"ee541470-2f04-4d6c-816a-554989d039e8"},"source":["batch_size = 64\n","train_x_list = [mnistm_train_x, svhn_train_x, usps_train_x]\n","val_x_list = [mnistm_val_x, svhn_val_x, usps_val_x]\n","test_x_list = [mnistm_test_x, svhn_test_x, usps_test_x]\n","train_y_list = [mnistm_train_y, svhn_train_y, usps_train_y]\n","val_y_list = [mnistm_val_y, svhn_val_y, usps_val_y]\n","test_y_list = [mnistm_test_y, svhn_test_y, usps_test_y]\n","for i in range(len(train_x_list)):\n","    train_set = ImgDataset(train_x_list[i], train_y_list[i], transform=train_transform)\n","    val_set = ImgDataset(val_x_list[i], val_y_list[i], transform=test_transform)\n","    test_set = ImgDataset(test_x_list[i], test_y_list[i], transform=test_transform)\n","    if i == 0: # mnistm\n","        mnistm_train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n","        mnistm_val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n","        mnistm_test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n","        print('finish mnistm_loader')\n","    elif i == 1: # svhn\n","        svhn_train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n","        svhn_val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n","        svhn_test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n","        print('finish svhn_loader')\n","    else: # usps\n","        usps_train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n","        usps_val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n","        usps_test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n","        print('finish usps_loader')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["finish mnistm_loader\n","finish svhn_loader\n","finish usps_loader\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mhkQxLwpM0fR"},"source":["# Training"]},{"cell_type":"markdown","metadata":{"id":"Ik_P4vh9kddj"},"source":["## function"]},{"cell_type":"code","metadata":{"id":"Pv7Nc6D5SM-t"},"source":["# reconstruction loss\n","class MSE(nn.Module):\n","    def __init__(self):\n","        super(MSE, self).__init__()\n","\n","    def forward(self, pred, real):\n","        diffs = torch.add(real, -pred) # return the difference between real, pred\n","        n = torch.numel(diffs.data) # return the number of elements in tensor\n","        mse = torch.sum(diffs.pow(2)) / n # return mse\n","\n","        return mse\n","\n","class SIMSE(nn.Module):\n","\n","    def __init__(self):\n","        super(SIMSE, self).__init__()\n","\n","    def forward(self, pred, real):\n","        diffs = torch.add(real, - pred) # return the difference between real, pred\n","        n = torch.numel(diffs.data) # return the number of elements in tensor\n","        simse = torch.sum(diffs).pow(2) / (n ** 2) # return simse\n","\n","        return simse\n","\n","# diff loss\n","class DiffLoss(nn.Module):\n","\n","    def __init__(self):\n","        super(DiffLoss, self).__init__()\n","\n","    def forward(self, input1, input2):\n","\n","        batch_size = input1.size(0)\n","        input1 = input1.view(batch_size, -1)\n","        input2 = input2.view(batch_size, -1)\n","\n","        input1_l2_norm = torch.norm(input1, p=2, dim=1, keepdim=True).detach() # L2 norm, dim=1\n","        input1_l2 = input1.div(input1_l2_norm.expand_as(input1) + 1e-6) # input1_l2_norm size: [batch_size, -1]\n","\n","        input2_l2_norm = torch.norm(input2, p=2, dim=1, keepdim=True).detach() # L2 norm, dim=1\n","        input2_l2 = input2.div(input2_l2_norm.expand_as(input2) + 1e-6) # input2_l2_norm size: [batch_size, -1]\n","\n","        diff_loss = torch.mean((input1_l2.t().mm(input2_l2)).pow(2)) # multiply\n","\n","        return diff_loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I3Nt-liE5a8u"},"source":["## DSN"]},{"cell_type":"markdown","metadata":{"id":"GTTVP5YU-v2M"},"source":["### USPS → MNIST-M"]},{"cell_type":"code","metadata":{"id":"49fnu3pbkgUz"},"source":["class DSN_PSE_USPS2MNISTM(nn.Module):\n","    # private source encoder\n","    def __init__(self, code_size=100):\n","        super(DSN_PSE_USPS2MNISTM, self).__init__()\n","        self.code_size = code_size\n","        self.source_encoder_conv = nn.Sequential(\n","            # input_size = (28, 28, 3)\n","            # output_size = (input_size-kernel_size+2*padding)/stride + 1\n","            nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3)), \n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            # [batch_size, 64, 32, 32]\n","\n","            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","            # [batch_size, 128, 32, 32]\n","\n","            nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","             # [batch_size, 256, 16, 16]\n","\n","            nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), \n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","            # [batch_size, 512, 8, 8]\n","\n","            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","            # [batch_size, 512, 4, 4]\n","\n","            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","            # [batch_size, 512, 2, 2]\n","\n","            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","            # [batch_size, 512, 1, 1]\n","        )\n","        self.source_encoder_fc = nn.Sequential(\n","            nn.Linear(in_features=1*1*512, out_features=code_size),\n","            nn.BatchNorm1d(code_size),\n","            nn.ReLU(),\n","            # [batch_size, code_size]\n","        )\n","\n","    def forward(self, input_data):\n","        private_feat = self.source_encoder_conv(input_data)\n","        private_feat = private_feat.view(-1, 512*1*1)\n","        private_code = self.source_encoder_fc(private_feat)\n","        return private_code\n","\n","\n","class DSN_PTE_USPS2MNISTM(nn.Module):\n","    # private target encoder\n","    def __init__(self, code_size=100):\n","        super(DSN_PTE_USPS2MNISTM, self).__init__()\n","        self.code_size = code_size\n","        self.target_encoder_conv = nn.Sequential(\n","            # input_size = (28, 28, 3)\n","            # output_size = (input_size-kernel_size+2*padding)/stride + 1\n","            nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3)), \n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            # [batch_size, 64, 32, 32]\n","\n","            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","            # [batch_size, 128, 32, 32]\n","\n","            nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","             # [batch_size, 256, 16, 16]\n","\n","            nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), \n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","            # [batch_size, 512, 8, 8]\n","\n","            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","            # [batch_size, 512, 4, 4]\n","\n","            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","            # [batch_size, 512, 2, 2]\n","\n","            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","            # [batch_size, 512, 1, 1]\n","        )\n","        self.target_encoder_fc = nn.Sequential(\n","            nn.Linear(in_features=1*1*512, out_features=code_size),\n","            nn.BatchNorm1d(code_size),\n","            nn.ReLU(),\n","            # [batch_size, code_size]\n","        )\n","\n","    def forward(self, input_data):\n","        private_feat = self.target_encoder_conv(input_data)\n","        private_feat = private_feat.view(-1, 512*1*1)\n","        private_code = self.target_encoder_fc(private_feat)\n","        return private_code\n","\n","\n","class DSN_SE_USPS2MNISTM(nn.Module):\n","    # private shared encoder\n","    def __init__(self, code_size=100):\n","        super(DSN_SE_USPS2MNISTM, self).__init__()\n","        self.shared_encoder_conv = nn.Sequential(\n","            # input_size = (28, 28, 3)\n","            # output_size = (input_size-kernel_size+2*padding)/stride + 1\n","            nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3)), \n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            # [batch_size, 64, 32, 32]\n","\n","            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","            # [batch_size, 128, 32, 32]\n","\n","            nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","             # [batch_size, 256, 16, 16]\n","\n","            nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), \n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","            # [batch_size, 512, 8, 8]\n","\n","            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","            # [batch_size, 512, 4, 4]\n","\n","            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","            # [batch_size, 512, 2, 2]\n","\n","            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","            # [batch_size, 512, 1, 1]\n","        )\n","        self.shared_encoder_fc = nn.Sequential(\n","            nn.Linear(in_features=1*1*512, out_features=code_size),\n","            nn.BatchNorm1d(code_size),\n","            nn.ReLU(),\n","            # [batch_size, code_size]\n","        )\n","\n","    def forward(self, input_data):\n","        # shared encoder\n","        shared_feat = self.shared_encoder_conv(input_data)\n","        shared_feat = shared_feat.view(-1, 512*1*1)\n","        shared_code = self.shared_encoder_fc(shared_feat)\n","        return shared_code\n","\n","class DSN_CC_USPS2MNISTM(nn.Module):\n","    # classify 10 numbers\n","    def __init__(self, code_size=512, n_class=10):\n","        super(DSN_CC_USPS2MNISTM, self).__init__()\n","        self.shared_encoder_pred_class = nn.Sequential(\n","            nn.Linear(code_size, 512),\n","            nn.ReLU(),\n","\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","\n","            nn.Linear(512, n_class),\n","            # [batch_size, 10]\n","        )\n","\n","    def forward(self, shared_code):\n","        # shared encoder\n","        class_label = self.shared_encoder_pred_class(shared_code)\n","        return class_label\n","\n","class DSN_DC_USPS2MNISTM(nn.Module):\n","    # classify two domain\n","    def __init__(self, code_size=512, n_class=10):\n","        super(DSN_DC_USPS2MNISTM, self).__init__()\n","        self.shared_encoder_pred_domain = nn.Sequential(\n","            nn.Linear(512, 512),\n","            nn.BatchNorm1d(512),\n","            nn.ReLU(),\n","\n","            nn.Linear(512, 512),\n","            nn.BatchNorm1d(512),\n","            nn.ReLU(),\n","\n","            nn.Linear(512, 512),\n","            nn.BatchNorm1d(512),\n","            nn.ReLU(),\n","\n","            nn.Linear(512, 512),\n","            nn.BatchNorm1d(512),\n","            nn.ReLU(),\n","\n","            nn.Linear(512, 1),\n","            # [batch_size, 1]\n","        )\n","\n","    def forward(self, shared_code):\n","        # shared encoder\n","        domain_label = self.shared_encoder_pred_domain(shared_code)\n","        return domain_label\n","\n","\n","class DSN_SD_USPS2MNISTM(nn.Module):\n","    # shared decoder\n","    def __init__(self, code_size=512):\n","        super(DSN_SD_USPS2MNISTM, self).__init__()\n","\n","        self.shared_decoder_fc = nn.Sequential(\n","            nn.Linear(in_features=code_size, out_features=588),\n","            nn.BatchNorm1d(588),\n","            nn.ReLU(),\n","            # [batch_size, 588]\n","        )\n","        self.shared_decoder_conv = nn.Sequential(\n","            nn.Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU(),\n","            # [batch_size, 16, 14, 14]\n","\n","            nn.Conv2d(16, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU(),\n","            # [batch_size, 16, 14, 14] \n","\n","            nn.Upsample(scale_factor=2),\n","            # [batch_size, 16, 28, 28] \n","\n","            nn.Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU(),\n","            # [batch_size, 16, 28, 28] \n","\n","            nn.Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            # [batch_size, 3, 28, 28]                   \n","        )\n","\n","    def forward(self, union_code):\n","        rec_vec = self.shared_decoder_fc(union_code)\n","        rec_vec = rec_vec.view(-1, 3, 14, 14)\n","        rec_code = self.shared_decoder_conv(rec_vec)\n","        return rec_code"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ywOrm8CT_ZUz"},"source":["### MNIST-M → SVHN"]},{"cell_type":"code","metadata":{"id":"JV4DwYDN_eT1"},"source":["class DSN_PSE_MNISTM2SVHN(nn.Module):\n","    # private source encoder\n","    def __init__(self, code_size=100):\n","        super(DSN_PSE_MNISTM2SVHN, self).__init__()\n","        self.code_size = code_size\n","        self.source_encoder_conv = nn.Sequential(\n","            # input_size = (28, 28, 3)\n","            # output_size = (input_size-kernel_size+2*padding)/stride + 1\n","            nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3)), \n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            # [batch_size, 64, 32, 32]\n","\n","            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","            # [batch_size, 128, 32, 32]\n","\n","            nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","             # [batch_size, 256, 16, 16]\n","\n","            nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), \n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","            # [batch_size, 512, 8, 8]\n","\n","            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","            # [batch_size, 512, 4, 4]\n","        )\n","        self.source_encoder_fc = nn.Sequential(\n","            nn.Linear(in_features=4*4*512, out_features=code_size),\n","            nn.BatchNorm1d(code_size),\n","            nn.ReLU(),\n","            # [batch_size, code_size]\n","        )\n","\n","    def forward(self, input_data):\n","        private_feat = self.source_encoder_conv(input_data)\n","        private_feat = private_feat.view(-1, 512*4*4)\n","        private_code = self.source_encoder_fc(private_feat)\n","        return private_code\n","\n","\n","class DSN_PTE_MNISTM2SVHN(nn.Module):\n","    # private target encoder\n","    def __init__(self, code_size=100):\n","        super(DSN_PTE_MNISTM2SVHN, self).__init__()\n","        self.code_size = code_size\n","        self.target_encoder_conv = nn.Sequential(\n","            # input_size = (28, 28, 3)\n","            # output_size = (input_size-kernel_size+2*padding)/stride + 1\n","            nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3)), \n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            # [batch_size, 64, 32, 32]\n","\n","            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","            # [batch_size, 128, 32, 32]\n","\n","            nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","             # [batch_size, 256, 16, 16]\n","\n","            nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), \n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","            # [batch_size, 512, 8, 8]\n","\n","            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","            # [batch_size, 512, 4, 4]\n","        )\n","        self.target_encoder_fc = nn.Sequential(\n","            nn.Linear(in_features=4*4*512, out_features=code_size),\n","            nn.BatchNorm1d(code_size),\n","            nn.ReLU(),\n","            # [batch_size, code_size]\n","        )\n","\n","    def forward(self, input_data):\n","        private_feat = self.target_encoder_conv(input_data)\n","        private_feat = private_feat.view(-1, 512*4*4)\n","        private_code = self.target_encoder_fc(private_feat)\n","        return private_code\n","\n","\n","class DSN_SE_MNISTM2SVHN(nn.Module):\n","    # private shared encoder\n","    def __init__(self, code_size=100):\n","        super(DSN_SE_MNISTM2SVHN, self).__init__()\n","        self.shared_encoder_conv = nn.Sequential(\n","            # input_size = (28, 28, 3)\n","            # output_size = (input_size-kernel_size+2*padding)/stride + 1\n","            nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3)), \n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            # [batch_size, 64, 32, 32]\n","\n","            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","            # [batch_size, 128, 32, 32]\n","\n","            nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","             # [batch_size, 256, 16, 16]\n","\n","            nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), \n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","            # [batch_size, 512, 8, 8]\n","\n","            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","            # [batch_size, 512, 4, 4]\n","        )\n","        self.shared_encoder_fc = nn.Sequential(\n","            nn.Linear(in_features=4*4*512, out_features=code_size),\n","            nn.BatchNorm1d(code_size),\n","            nn.ReLU(),\n","            # [batch_size, code_size]\n","        )\n","\n","    def forward(self, input_data):\n","        # shared encoder\n","        shared_feat = self.shared_encoder_conv(input_data)\n","        shared_feat = shared_feat.view(-1, 512*4*4)\n","        shared_code = self.shared_encoder_fc(shared_feat)\n","        return shared_code\n","\n","class DSN_CC_MNISTM2SVHN(nn.Module):\n","    # classify 10 numbers\n","    def __init__(self, code_size=512, n_class=10):\n","        super(DSN_CC_MNISTM2SVHN, self).__init__()\n","        self.shared_encoder_pred_class = nn.Sequential(\n","            nn.Linear(code_size, 512),\n","            nn.ReLU(),\n","\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","\n","            nn.Linear(512, n_class),\n","            # [batch_size, 10]\n","        )\n","\n","    def forward(self, shared_code):\n","        # shared encoder\n","        class_label = self.shared_encoder_pred_class(shared_code)\n","        return class_label\n","\n","class DSN_DC_MNISTM2SVHN(nn.Module):\n","    # classify two domain\n","    def __init__(self, code_size=512, n_class=10):\n","        super(DSN_DC_MNISTM2SVHN, self).__init__()\n","        self.shared_encoder_pred_domain = nn.Sequential(\n","            nn.Linear(512, 512),\n","            nn.BatchNorm1d(512),\n","            nn.ReLU(),\n","\n","            nn.Linear(512, 512),\n","            nn.BatchNorm1d(512),\n","            nn.ReLU(),\n","\n","            nn.Linear(512, 512),\n","            nn.BatchNorm1d(512),\n","            nn.ReLU(),\n","\n","            nn.Linear(512, 512),\n","            nn.BatchNorm1d(512),\n","            nn.ReLU(),\n","\n","            nn.Linear(512, 1),\n","            # [batch_size, 1]\n","        )\n","\n","    def forward(self, shared_code):\n","        # shared encoder\n","        domain_label = self.shared_encoder_pred_domain(shared_code)\n","        return domain_label\n","\n","\n","class DSN_SD_MNISTM2SVHN(nn.Module):\n","    # shared decoder\n","    def __init__(self, code_size=512):\n","        super(DSN_SD_MNISTM2SVHN, self).__init__()\n","\n","        self.shared_decoder_fc = nn.Sequential(\n","            nn.Linear(in_features=code_size, out_features=588),\n","            nn.BatchNorm1d(588),\n","            nn.ReLU(),\n","            # [batch_size, 588]\n","        )\n","        self.shared_decoder_conv = nn.Sequential(\n","            nn.Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU(),\n","            # [batch_size, 16, 14, 14]\n","\n","            nn.Conv2d(16, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU(),\n","            # [batch_size, 16, 14, 14] \n","\n","            nn.Upsample(scale_factor=2),\n","            # [batch_size, 16, 28, 28] \n","\n","            nn.Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU(),\n","            # [batch_size, 16, 28, 28] \n","\n","            nn.Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            # [batch_size, 3, 28, 28]                   \n","        )\n","\n","    def forward(self, union_code):\n","        rec_vec = self.shared_decoder_fc(union_code)\n","        rec_vec = rec_vec.view(-1, 3, 14, 14)\n","        rec_code = self.shared_decoder_conv(rec_vec)\n","        return rec_code"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H_zVMpfe_nNM"},"source":["### SVHN → USPS"]},{"cell_type":"code","metadata":{"id":"rNzOHhsf_srW"},"source":["class DSN_PSE_SVHN2USPS(nn.Module):\n","    # private source encoder\n","    def __init__(self, code_size=100):\n","        super(DSN_PSE_SVHN2USPS, self).__init__()\n","        self.code_size = code_size\n","        self.source_encoder_conv = nn.Sequential(\n","            # input_size = (28, 28, 3)\n","            # output_size = (input_size-kernel_size+2*padding)/stride + 1\n","            nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3)), \n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            # [batch_size, 64, 32, 32]\n","\n","            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","            # [batch_size, 128, 32, 32]\n","\n","            nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","             # [batch_size, 256, 16, 16]\n","\n","            nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), \n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","            # [batch_size, 512, 8, 8]\n","\n","            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","            # [batch_size, 512, 4, 4]\n","\n","            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","            # [batch_size, 512, 2, 2]\n","\n","            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","            # [batch_size, 512, 1, 1]\n","        )\n","        self.source_encoder_fc = nn.Sequential(\n","            nn.Linear(in_features=1*1*512, out_features=code_size),\n","            nn.BatchNorm1d(code_size),\n","            nn.ReLU(),\n","            # [batch_size, code_size]\n","        )\n","\n","    def forward(self, input_data):\n","        private_feat = self.source_encoder_conv(input_data)\n","        private_feat = private_feat.view(-1, 512*1*1)\n","        private_code = self.source_encoder_fc(private_feat)\n","        return private_code\n","\n","\n","class DSN_PTE_SVHN2USPS(nn.Module):\n","    # private target encoder\n","    def __init__(self, code_size=100):\n","        super(DSN_PTE_SVHN2USPS, self).__init__()\n","        self.code_size = code_size\n","        self.target_encoder_conv = nn.Sequential(\n","            # input_size = (28, 28, 3)\n","            # output_size = (input_size-kernel_size+2*padding)/stride + 1\n","            nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3)), \n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            # [batch_size, 64, 32, 32]\n","\n","            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","            # [batch_size, 128, 32, 32]\n","\n","            nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","             # [batch_size, 256, 16, 16]\n","\n","            nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), \n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","            # [batch_size, 512, 8, 8]\n","\n","            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","            # [batch_size, 512, 4, 4]\n","\n","            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","            # [batch_size, 512, 2, 2]\n","\n","            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","            # [batch_size, 512, 1, 1]\n","        )\n","        self.target_encoder_fc = nn.Sequential(\n","            nn.Linear(in_features=1*1*512, out_features=code_size),\n","            nn.BatchNorm1d(code_size),\n","            nn.ReLU(),\n","            # [batch_size, code_size]\n","        )\n","\n","    def forward(self, input_data):\n","        private_feat = self.target_encoder_conv(input_data)\n","        private_feat = private_feat.view(-1, 512*1*1)\n","        private_code = self.target_encoder_fc(private_feat)\n","        return private_code\n","\n","\n","class DSN_SE_SVHN2USPS(nn.Module):\n","    # private shared encoder\n","    def __init__(self, code_size=100):\n","        super(DSN_SE_SVHN2USPS, self).__init__()\n","        self.shared_encoder_conv = nn.Sequential(\n","            # input_size = (28, 28, 3)\n","            # output_size = (input_size-kernel_size+2*padding)/stride + 1\n","            nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3)), \n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            # [batch_size, 64, 32, 32]\n","\n","            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","            # [batch_size, 128, 32, 32]\n","\n","            nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","             # [batch_size, 256, 16, 16]\n","\n","            nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), \n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","            # [batch_size, 512, 8, 8]\n","\n","            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","            # [batch_size, 512, 4, 4]\n","\n","            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","            # [batch_size, 512, 2, 2]\n","\n","            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","            # [batch_size, 512, 1, 1]\n","        )\n","        self.shared_encoder_fc = nn.Sequential(\n","            nn.Linear(in_features=1*1*512, out_features=code_size),\n","            nn.BatchNorm1d(code_size),\n","            nn.ReLU(),\n","            # [batch_size, code_size]\n","        )\n","\n","    def forward(self, input_data):\n","        # shared encoder\n","        shared_feat = self.shared_encoder_conv(input_data)\n","        shared_feat = shared_feat.view(-1, 512*1*1)\n","        shared_code = self.shared_encoder_fc(shared_feat)\n","        return shared_code\n","\n","class DSN_CC_SVHN2USPS(nn.Module):\n","    # classify 10 numbers\n","    def __init__(self, code_size=512, n_class=10):\n","        super(DSN_CC_SVHN2USPS, self).__init__()\n","        self.shared_encoder_pred_class = nn.Sequential(\n","            nn.Linear(code_size, 512),\n","            nn.ReLU(),\n","\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","\n","            nn.Linear(512, n_class),\n","            # [batch_size, 10]\n","        )\n","\n","    def forward(self, shared_code):\n","        # shared encoder\n","        class_label = self.shared_encoder_pred_class(shared_code)\n","        return class_label\n","\n","class DSN_DC_SVHN2USPS(nn.Module):\n","    # classify two domain\n","    def __init__(self, code_size=512, n_class=10):\n","        super(DSN_DC_SVHN2USPS, self).__init__()\n","        self.shared_encoder_pred_domain = nn.Sequential(\n","            nn.Linear(512, 512),\n","            nn.BatchNorm1d(512),\n","            nn.ReLU(),\n","\n","            nn.Linear(512, 512),\n","            nn.BatchNorm1d(512),\n","            nn.ReLU(),\n","\n","            nn.Linear(512, 512),\n","            nn.BatchNorm1d(512),\n","            nn.ReLU(),\n","\n","            nn.Linear(512, 512),\n","            nn.BatchNorm1d(512),\n","            nn.ReLU(),\n","\n","            nn.Linear(512, 1),\n","            # [batch_size, 1]\n","        )\n","\n","    def forward(self, shared_code):\n","        # shared encoder\n","        domain_label = self.shared_encoder_pred_domain(shared_code)\n","        return domain_label\n","\n","\n","class DSN_SD_SVHN2USPS(nn.Module):\n","    # shared decoder\n","    def __init__(self, code_size=512):\n","        super(DSN_SD_SVHN2USPS, self).__init__()\n","\n","        self.shared_decoder_fc = nn.Sequential(\n","            nn.Linear(in_features=code_size, out_features=588),\n","            nn.BatchNorm1d(588),\n","            nn.ReLU(),\n","            # [batch_size, 588]\n","        )\n","        self.shared_decoder_conv = nn.Sequential(\n","            nn.Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU(),\n","            # [batch_size, 16, 14, 14]\n","\n","            nn.Conv2d(16, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU(),\n","            # [batch_size, 16, 14, 14] \n","\n","            nn.Upsample(scale_factor=2),\n","            # [batch_size, 16, 28, 28] \n","\n","            nn.Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU(),\n","            # [batch_size, 16, 28, 28] \n","\n","            nn.Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            # [batch_size, 3, 28, 28]                   \n","        )\n","\n","    def forward(self, union_code):\n","        rec_vec = self.shared_decoder_fc(union_code)\n","        rec_vec = rec_vec.view(-1, 3, 14, 14)\n","        rec_code = self.shared_decoder_conv(rec_vec)\n","        return rec_code"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0JziEgfzkehb"},"source":["## training"]},{"cell_type":"code","metadata":{"id":"7q2m4OjJA4ke"},"source":["def set_model(target_domain_name):\n","    if target_domain_name == 'mnistm':\n","        DSN_PSE_model_temp = DSN_PSE_USPS2MNISTM(512).cuda()   # private source encoder\n","        DSN_PTE_model_temp = DSN_PTE_USPS2MNISTM(512).cuda()   # private target encoder\n","        DSN_SE_model_temp = DSN_SE_USPS2MNISTM(512).cuda()     # share encoder\n","        DSN_CC_model_temp = DSN_CC_USPS2MNISTM(512, 10).cuda() # class classifier\n","        DSN_DC_model_temp = DSN_DC_USPS2MNISTM(512, 1).cuda()  # doamin classifier\n","        DSN_SD_model_temp = DSN_SD_USPS2MNISTM(512).cuda()     # share decoder \n","    elif target_domain_name == 'svhn':\n","        DSN_PSE_model_temp = DSN_PSE_MNISTM2SVHN(512).cuda()   # private source encoder\n","        DSN_PTE_model_temp = DSN_PTE_MNISTM2SVHN(512).cuda()   # private target encoder\n","        DSN_SE_model_temp = DSN_SE_MNISTM2SVHN(512).cuda()     # share encoder\n","        DSN_CC_model_temp = DSN_CC_MNISTM2SVHN(512, 10).cuda() # class classifier\n","        DSN_DC_model_temp = DSN_DC_MNISTM2SVHN(512, 1).cuda()  # doamin classifier\n","        DSN_SD_model_temp = DSN_SD_MNISTM2SVHN(512).cuda()     # share decoder \n","    else:\n","        DSN_PSE_model_temp = DSN_PSE_SVHN2USPS(512).cuda()   # private source encoder\n","        DSN_PTE_model_temp = DSN_PTE_SVHN2USPS(512).cuda()   # private target encoder\n","        DSN_SE_model_temp = DSN_SE_SVHN2USPS(512).cuda()     # share encoder\n","        DSN_CC_model_temp = DSN_CC_SVHN2USPS(512, 10).cuda() # class classifier\n","        DSN_DC_model_temp = DSN_DC_SVHN2USPS(512, 1).cuda()  # doamin classifier\n","        DSN_SD_model_temp = DSN_SD_SVHN2USPS(512).cuda()     # share decoder \n","    \n","    return DSN_PSE_model_temp, DSN_PTE_model_temp, DSN_SE_model_temp, DSN_CC_model_temp, DSN_DC_model_temp, DSN_SD_model_temp\n","\n","def set_loader(target_domain_name):\n","    if target_domain_name == 'mnistm':\n","        source_train_loader_temp = usps_train_loader\n","        target_train_loader_temp = mnistm_train_loader\n","        target_val_loader_temp = mnistm_val_loader\n","    elif target_domain_name == 'svhn':\n","        source_train_loader_temp = mnistm_train_loader\n","        target_train_loader_temp = svhn_train_loader\n","        target_val_loader_temp = svhn_val_loader\n","    else:\n","        source_train_loader_temp = svhn_train_loader\n","        target_train_loader_temp = usps_train_loader\n","        target_val_loader_temp = usps_val_loader\n","\n","    return source_train_loader_temp, target_train_loader_temp, target_val_loader_temp\n","\n","def set_hyperparameter(num_epoch, alpha_weight, beta_weight, gamma_weight):\n","    num_epoch_temp = num_epoch\n","    alpha_weight_temp = alpha_weight\n","    beta_weight_temp = beta_weight\n","    gamma_weight_temp = gamma_weight\n","    best_val_acc_temp = 0.0\n","\n","    return num_epoch_temp, alpha_weight_temp, beta_weight_temp, gamma_weight_temp, best_val_acc_temp"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Xouo6RTw5SV"},"source":["# set model\n","DSN_PSE_model, DSN_PTE_model, DSN_SE_model, DSN_CC_model, DSN_DC_model, DSN_SD_model = set_model('usps')\n","\n","# set loss function\n","loss_classification = nn.CrossEntropyLoss()\n","loss_recon_mse = MSE().cuda()\n","loss_recon_simse = SIMSE().cuda()\n","loss_diff = DiffLoss().cuda()\n","loss_similarity = nn.BCEWithLogitsLoss()\n","\n","# set optimizer\n","optimizer_PSE = torch.optim.Adam(DSN_PSE_model.parameters(), lr=0.001)\n","optimizer_PTE = torch.optim.Adam(DSN_PTE_model.parameters(), lr=0.001)\n","optimizer_SE = torch.optim.Adam(DSN_SE_model.parameters(), lr=0.001)\n","optimizer_CC = torch.optim.Adam(DSN_CC_model.parameters(), lr=0.001)\n","optimizer_DC = torch.optim.Adam(DSN_DC_model.parameters(), lr=0.001)\n","optimizer_SD = torch.optim.Adam(DSN_SD_model.parameters(), lr=0.001)\n","\n","# set hyperparameter\n","# USPS → MNIST-M: 50, 0.01, 0.07, 0.25\n","# SVHN → USPS: 50, 0.01, 0.07, 0.1 訓練時前面會一直出現 0.1316 正常\n","num_epoch, alpha_weight, beta_weight, gamma_weight, best_val_acc = set_hyperparameter(200, 0.01, 0.07, 0.1)\n","\n","# set loader: USPS → MNIST-M / MNIST-M → SVHN / SVHN → USPS\n","source_train_loader, target_train_loader, target_val_loader = set_loader('usps')\n","\n","for epoch in range(num_epoch):\n","\n","    DSN_PSE_model.train()\n","    DSN_PTE_model.train()\n","    DSN_SE_model.train()\n","    DSN_CC_model.train()\n","    DSN_DC_model.train()\n","    DSN_SD_model.train()\n","\n","    training_epoch_time = time.time()\n","    ReconLoss = 0.0\n","    DifferLoss = 0.0\n","    SimLoss = 0.0\n","    PredLoss = 0.0\n","    target_val_acc = 0.0\n","    target_val_num = 0.0\n","\n","    for x, ((source_data, source_label), (target_train_data, _)) in enumerate(zip(source_train_loader, target_train_loader)):\n","\n","        source_data = source_data.cuda()\n","        source_label = source_label.cuda()\n","        target_train_data = target_train_data.cuda()\n","        # 我們把source data和target data混在一起，否則batch_norm可能會算錯 (兩邊的data的mean/var不太一樣)\n","        mixed_data = torch.cat([source_data, target_train_data], dim=0)\n","        domain_label = torch.zeros([source_data.shape[0] + target_train_data.shape[0], 1]).cuda()\n","        # 設定source data的label為1\n","        domain_label[:source_data.shape[0]] = 1 # source label = 1\n","\n","        # Step 1 : 訓練 Domain Classifier\n","        mix_share_encode = DSN_SE_model(mixed_data)\n","        mix_pred_label_domain = DSN_DC_model(mix_share_encode.detach())\n","        # loss = gamma_weight*loss_similarity(mix_pred_label_domain, domain_label) USPS → MNIST-M need gamma\n","        loss = loss_similarity(mix_pred_label_domain, domain_label)\n","        SimLoss += loss.item()\n","        loss.backward()\n","        optimizer_DC.step()\n","\n","        # Step 2 : 訓練 Share Encoder 和 Class Classifier\n","        mix_pred_label_class = DSN_CC_model(mix_share_encode[:source_data.shape[0]])\n","        mix_pred_label_domain = DSN_DC_model(mix_share_encode)\n","        # loss 為原本的 class CE - lamb * domain BCE，相減的原因同 GAN 中的 Discriminator 中的 G loss。\n","        loss = loss_classification(mix_pred_label_class, source_label) - gamma_weight*loss_similarity(mix_pred_label_domain, domain_label)\n","        PredLoss += loss.item()\n","        loss.backward()\n","        optimizer_SE.step()\n","        optimizer_CC.step()\n","        optimizer_SE.zero_grad()\n","\n","        # Step 3 : 訓練 Private Source Encoder, Private Target Encoder, Share Encoder, Share Decoder\n","        source_privte_encode = DSN_PSE_model(source_data)\n","        target_privte_encode = DSN_PTE_model(target_train_data)\n","        mix_share_encode = DSN_SE_model(mixed_data)\n","        mix_share_encode[:source_data.shape[0]] += source_privte_encode\n","        mix_share_encode[source_data.shape[0]:] += target_privte_encode\n","        mix_share_decode = DSN_SD_model(mix_share_encode)\n","        loss = alpha_weight*loss_recon_mse(mix_share_decode, mixed_data) + alpha_weight*loss_recon_simse(mix_share_decode, mixed_data)\n","        ReconLoss += loss.item()\n","        loss.backward()\n","        optimizer_PSE.step()\n","        optimizer_PTE.step()\n","        optimizer_SE.step()\n","        optimizer_SD.step()\n","\n","        optimizer_CC.zero_grad()\n","        optimizer_DC.zero_grad()\n","        optimizer_SD.zero_grad()\n","        optimizer_PSE.zero_grad()\n","        optimizer_PTE.zero_grad()\n","        optimizer_SE.zero_grad()\n","\n","    DSN_SE_model.eval()\n","    DSN_CC_model.eval()\n","\n","    with torch.no_grad():\n","        for i, (target_val_data, target_val_label) in enumerate(target_val_loader):\n","            target_val_data = target_val_data.cuda()\n","            target_val_label = target_val_label.cuda()\n","            target_val_share_encode = DSN_SE_model(target_val_data)\n","            target_val_pred_label = DSN_CC_model(target_val_share_encode)\n","            target_val_acc += torch.sum(torch.argmax(target_val_pred_label, dim=1) == target_val_label).item()\n","            target_val_num += target_val_data.shape[0]\n","    if target_val_acc > best_val_acc:\n","        best_val_acc = target_val_acc\n","        torch.save(DSN_SE_model.state_dict(), os.path.join(path, 'p4_SVHN2USPS_DSN_SE_model.pkl'))\n","        torch.save(DSN_CC_model.state_dict(), os.path.join(path, 'p4_SVHN2USPS_DSN_CC_model.pkl'))\n","        print('save model')\n","\n","    print('epoch : {}, training epoch time: {:.4f} (sec)'.format(epoch, time.time()-training_epoch_time))\n","    print('target val acc: {:.4f}, best val acc: {:.4f}'.format(\n","        target_val_acc/target_val_num, best_val_acc/target_val_num\n","    ))\n","    print('recon_loss: {:.7f}, diff_loss: {:.7f}, sim_loss: {:.7f}, pred_loss: {:.7f}'.format(\n","        ReconLoss, DifferLoss, SimLoss, PredLoss\n","    ))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sQStEYVokfVs"},"source":["## testing"]},{"cell_type":"code","metadata":{"id":"tp2cEU6UWEIr"},"source":["def prediction_output(target_domain_loader, target_domain_name, output_path):\n","    if target_domain_name == 'mnistm':\n","        DSN_SE_model = DSN_SE_USPS2MNISTM(512).cuda()     # share encoder\n","        DSN_CC_model = DSN_CC_USPS2MNISTM(512, 10).cuda() # class classifier\n","        DSN_SE_model.load_state_dict(torch.load(os.path.join(path, 'p4_USPS2MNISTM_DSN_SE_model.pkl')))\n","        DSN_CC_model.load_state_dict(torch.load(os.path.join(path, 'p4_USPS2MNISTM_DSN_CC_model.pkl')))\n","        test_index = mnistm_test_index\n","    elif target_domain_name == 'svhn':\n","        DSN_SE_model = DSN_SE_MNISTM2SVHN(512).cuda()     # share encoder\n","        DSN_CC_model = DSN_CC_MNISTM2SVHN(512, 10).cuda() # class classifier\n","        DSN_SE_model.load_state_dict(torch.load(os.path.join(path, 'p4_MNISTM2SVHN_DSN_SE_model.pkl')))\n","        DSN_CC_model.load_state_dict(torch.load(os.path.join(path, 'p4_MNISTM2SVHN_DSN_CC_model.pkl')))\n","        test_index = svhn_test_index\n","    else: # target_domain_name == 'usps'\n","        DSN_SE_model = DSN_SE_SVHN2USPS(512).cuda()     # share encoder\n","        DSN_CC_model = DSN_CC_SVHN2USPS(512, 10).cuda() # class classifier\n","        DSN_SE_model.load_state_dict(torch.load(os.path.join(path, 'p4_SVHN2USPS_DSN_SE_model.pkl')))\n","        DSN_CC_model.load_state_dict(torch.load(os.path.join(path, 'p4_SVHN2USPS_DSN_CC_model.pkl')))\n","        test_index = usps_test_index\n","\n","    target_test_acc = 0.0\n","    target_test_num = 0.0\n","    initial = True\n","    DSN_SE_model.eval()\n","    DSN_CC_model.eval()\n","\n","    with torch.no_grad():\n","        for i, (target_test_data, target_test_label) in enumerate(target_domain_loader):\n","            # Step 4 : test Domain Classifier on testing data\n","            target_test_data = target_test_data.cuda()\n","            target_test_label = target_test_label.cuda()\n","            feature = DSN_SE_model(target_test_data)\n","            class_logits = DSN_CC_model(feature)\n","            if initial == True:\n","                prediction = torch.argmax(class_logits, dim=1).data.cpu().numpy()\n","                initial = False\n","            else:\n","                prediction = np.concatenate((prediction, torch.argmax(class_logits, dim=1).data.cpu().numpy()), axis=0)\n","            target_test_acc += torch.sum(torch.argmax(class_logits, dim=1) == target_test_label).item()\n","            target_test_num += target_test_data.shape[0]\n","    print(target_domain_name + ' target test acc: {:.4f}'.format(target_test_acc/target_test_num))\n","\n","    # Generate prediction submission\n","    prediction_name = output_path\n","    df = pd.DataFrame({'image_name': test_index, 'label': prediction})\n","    df.to_csv(prediction_name, index=False)\n","    return df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CogQ9FDUW713"},"source":["df_mnistm = prediction_output(mnistm_test_loader, 'mnistm', 'test_pred_mnistm.csv')\n","df_svhn = prediction_output(svhn_test_loader, 'svhn', 'test_pred_svhn.csv')\n","df_usps = prediction_output(usps_test_loader, 'usps', 'test_pred_usps.csv')\n","\n","# from google.colab import files\n","# files.download('test_pred.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nrQ0Kx4Zo-Zq"},"source":["#Report (35%)"]},{"cell_type":"markdown","metadata":{"id":"pBuv7858nAJZ"},"source":["1. Compute the accuracy on target domain, while the model is trained on\n","source and target domain. (domain adaptation) (6+10%)   \n","• Use source images and labels + target images for training    \n","    **You should implement UDA methods other than DANN for your improved UDA model. Some methods are provided at the end of Problem 4 description (page 14).**"]},{"cell_type":"code","metadata":{"id":"34G-68elBoOQ"},"source":["# set model\n","for task in ['mnistm', 'svhn', 'usps']:\n","    DSN_PSE_model, DSN_PTE_model, DSN_SE_model, DSN_CC_model, DSN_DC_model, DSN_SD_model = set_model(task)\n","    print('------------------------------------------------', task, '------------------------------------------------')\n","    print(DSN_PSE_model)\n","    print(DSN_PTE_model)\n","    print(DSN_SE_model)\n","    print(DSN_CC_model)\n","    print(DSN_DC_model)\n","    print(DSN_SD_model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L0PiBdf_FZhw"},"source":["2. Visualize the the latent space by mapping the testing images to 2D space\n","(with t-SNE) and use different colors to indicate data of (a) different\n","digits classes 0-9 and (b) different domains (source/target). (6%)    \n","• Note that you need to plot the figures of all the three scenarios, so you would need to plot 6 figures in total in this sub-problem."]},{"cell_type":"code","metadata":{"id":"LwTz80IuFe8Q"},"source":["# visialize the latent space\n","def visialize_latent(target_mode):\n","    if target_mode == 'mnistm':\n","        DSN_SE_model = DSN_SE_USPS2MNISTM(512).cuda()\n","        DSN_SE_model.load_state_dict(torch.load(os.path.join(path, 'p4_USPS2MNISTM_DSN_SE_model.pkl')))\n","        source_test_loader = usps_test_loader\n","        target_test_loader = mnistm_test_loader\n","    elif target_mode == 'svhn':\n","        DSN_SE_model = DSN_SE_MNISTM2SVHN(512).cuda()\n","        DSN_SE_model.load_state_dict(torch.load(os.path.join(path, 'p4_MNISTM2SVHN_DSN_SE_model.pkl')))\n","        source_test_loader = mnistm_test_loader\n","        target_test_loader = svhn_test_loader\n","    else: # usps\n","        DSN_SE_model = DSN_SE_SVHN2USPS(512).cuda()\n","        DSN_SE_model.load_state_dict(torch.load(os.path.join(path, 'p4_SVHN2USPS_DSN_SE_model.pkl')))\n","        source_test_loader = svhn_test_loader\n","        target_test_loader = usps_test_loader\n","    DSN_SE_model.eval()\n","    feature_source = torch.tensor([]).cuda()\n","    feature_target = torch.tensor([]).cuda()\n","    with torch.no_grad():\n","        for i, (source_test_data, _) in enumerate(source_test_loader):\n","            source_test_data = source_test_data.cuda()\n","            feature = DSN_SE_model(source_test_data)\n","            feature_source = torch.cat((feature_source, feature), 0)\n","        feature_source = feature_source.data.cpu().numpy()\n","\n","        for i, (target_test_data, _) in enumerate(target_test_loader):\n","            target_test_data = target_test_data.cuda()\n","            feature = DSN_SE_model(target_test_data)\n","            feature_target = torch.cat((feature_target, feature), 0)\n","        feature_target = feature_target.data.cpu().numpy()\n","\n","        return feature_source, feature_target\n","\n","target_mode_list = ['mnistm', 'svhn', 'usps']\n","for target_mode in target_mode_list:\n","    if target_mode == 'mnistm':\n","        feature_USPS2MNISTM_source, feature_USPS2MNISTM_target = visialize_latent(target_mode)\n","        feature_USPS2MNISTM = np.concatenate((feature_USPS2MNISTM_source, feature_USPS2MNISTM_target), axis=0)\n","        class_USPS2MNISTM = np.concatenate((usps_test_y, mnistm_test_y), axis=0)\n","        domain_USPS2MNISTM = np.concatenate((np.zeros((len(usps_test_y),), dtype=np.int), np.ones((len(mnistm_test_y),), dtype=np.int)), axis=0)\n","    elif target_mode == 'svhn':\n","        feature_MNISTM2SVHN_source, feature_MNISTM2SVHN_target = visialize_latent(target_mode)\n","        feature_MNISTM2SVHN = np.concatenate((feature_MNISTM2SVHN_source, feature_MNISTM2SVHN_target), axis=0)\n","        class_MNISTM2SVHN = np.concatenate((mnistm_test_y, svhn_test_y), axis=0)\n","        domain_MNISTM2SVHN = np.concatenate((np.zeros((len(mnistm_test_y),), dtype=np.int), np.ones((len(svhn_test_y),), dtype=np.int)), axis=0)\n","    else:\n","        feature_SVHN2USPS_source, feature_SVHN2USPS_target = visialize_latent(target_mode)\n","        feature_SVHN2USPS = np.concatenate((feature_SVHN2USPS_source, feature_SVHN2USPS_target), axis=0)\n","        class_SVHN2USPS = np.concatenate((svhn_test_y, usps_test_y), axis=0)\n","        domain_SVHN2USPS = np.concatenate((np.zeros((len(svhn_test_y),), dtype=np.int), np.ones((len(usps_test_y),), dtype=np.int)), axis=0)\n","    print('finish ' + target_mode + ' latent')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pxROyxJIJsov"},"source":["# tsne\n","feature_USPS2MNISTM_embedded = manifold.TSNE(n_components=2, perplexity=30.0, random_state=0, n_iter=250).fit_transform(feature_USPS2MNISTM)\n","print('finish feature_USPS2MNISTM_embedded')\n","feature_MNISTM2SVHN_embedded = manifold.TSNE(n_components=2, perplexity=30.0, random_state=0, n_iter=250).fit_transform(feature_MNISTM2SVHN)\n","print('finish feature_MNISTM2SVHN_embedded')\n","feature_SVHN2USPS_embedded = manifold.TSNE(n_components=2, perplexity=30.0, random_state=0, n_iter=250).fit_transform(feature_SVHN2USPS)\n","print('finish feature_SVHN2USPS_embedded')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VSmhh8XmJvXS"},"source":["np.save(os.path.join(path, 'p4_feature_USPS2MNISTM_embedded.npy'), feature_USPS2MNISTM_embedded)\n","np.save(os.path.join(path, 'p4_feature_MNISTM2SVHN_embedded.npy'), feature_MNISTM2SVHN_embedded)\n","np.save(os.path.join(path, 'p4_feature_SVHN2USPS_embedded.npy'), feature_SVHN2USPS_embedded)\n","feature_USPS2MNISTM_embedded = np.load(os.path.join(path, 'p4_feature_USPS2MNISTM_embedded.npy'))\n","feature_MNISTM2SVHN_embedded = np.load(os.path.join(path, 'p4_feature_MNISTM2SVHN_embedded.npy'))\n","feature_SVHN2USPS_embedded = np.load(os.path.join(path, 'p4_feature_SVHN2USPS_embedded.npy'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i1WhF8WgJxDi"},"source":["plt.figure(figsize=(16, 16))\n","color_map = ['blue', 'orange', 'green', 'red', 'purple', 'brown', 'pink', 'gray', 'olive', 'cyan']\n","\n","for i in range(6):\n","    plt.subplot(2, 3, i+1)\n","    if i%3 == 0: # USPS2MNISTM\n","        X_tsne = feature_USPS2MNISTM_embedded\n","        if i == 0: # num\n","            y = class_USPS2MNISTM\n","            plt.title('feature_USPS2MNISTM class')\n","        else: # domain\n","            y = domain_USPS2MNISTM\n","            plt.title('feature_USPS2MNISTM domain')\n","\n","    elif i%3 == 1: # USPS2MNISTM\n","        X_tsne = feature_MNISTM2SVHN_embedded\n","        if i == 1: # num\n","            y = class_MNISTM2SVHN\n","            plt.title('feature_MNISTM2SVHN class')\n","        else: # domain\n","            y = domain_MNISTM2SVHN\n","            plt.title('feature_MNISTM2SVHN domain')\n","    else: # i == 2 or i == 5 SVHN2USPS     \n","        X_tsne = feature_SVHN2USPS_embedded\n","        if i == 2: # num\n","            y = class_SVHN2USPS\n","            plt.title('feature_SVHN2USPS class')\n","        else: #  domain \n","            y = domain_SVHN2USPS\n","            plt.title('feature_SVHN2USPS domain')\n","    print('ok')      \n","\n","    x_min, x_max = X_tsne.min(0), X_tsne.max(0)\n","    X_norm = (X_tsne - x_min) / (x_max - x_min)  # normalize\n","    for i in range(X_norm.shape[0]):\n","        plt.text(X_norm[i, 0], X_norm[i, 1], str(y[i]), color=color_map[y[i]], fontdict={'weight': 'bold', 'size': 9})\n","    plt.xticks([])\n","    plt.yticks([])\n","\n","plt.savefig(os.path.join(path, 'p4_tsne_feature.jpg'))\n","print('save tsne image')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ce9ReCB8FfGg"},"source":["3. Describe the architecture & implementation detail of your model. (6%)"]},{"cell_type":"markdown","metadata":{"id":"4-17sQdjKlbn"},"source":["4. Discuss what you’ve observed and learned from implementing your improved UDA model. (7%)"]}]}